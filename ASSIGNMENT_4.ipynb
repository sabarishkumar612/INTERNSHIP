{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68de26b5",
   "metadata": {},
   "source": [
    "# PROBLEM NO.9 - DATA SCIENCE RECRUITERS - NAUKRI WEBSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ab7c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d5c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1=webdriver.Chrome(r\"chromedriver.exe\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fcbb478",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver1.get(\"https://www.naukri.com/hr-recruiters-consultants\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d886297",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver1.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\")\n",
    "designation.send_keys('Data Science') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bb06393",
   "metadata": {},
   "outputs": [],
   "source": [
    "search1=driver1.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button\")\n",
    "search1.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c35ffc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classic ASP Developer, Internet Marketing Professional, Data Science SME, Content Writers, SEO Professional, Revenue Professional',\n",
       " '.Net, Java, Data Science, Linux Administration, Sql Server Development, Winforms, Wcf Services, Wpf, Telecom Engineering, Technical Management, Software',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Business Analytics, Deep Learning, statistics, Data Analytics, Data Analysis, support vector machine',\n",
       " 'Mean Stack, javascript, angularjs, mongodb, Web Services, rest, express, Node.js, Big Data, iot, Data Science, Cloud Computing, saas, Aws',\n",
       " 'Hadoop, Spark, Digital Strategy, Data Architecture, Command Center, Cdp, Dmp, Kafka, Data Science, Data Analysis, Big Data Analytics, Real Time Analysis, SQL',\n",
       " 'Analytics, Business Intelligence, Business Analytics, Predictive Modeling, Predictive Analytics, Data Science, Data Analysis, Data Analytics, Big Data, Big',\n",
       " 'Data Science',\n",
       " 'Machine Learning, algorithms, Go Getter, Computer Science, spark, Big Data, hdfs, sql, cassandra, hadoop, python, scala, java, Data Science, Front End',\n",
       " 'Technical Training, Software Development, Presentation Skills, B.tech, M.tech, B.e., mca, msc, Computer Science, freshers, jobs in indore, Data Science, itil',\n",
       " 'Software Development, It Sales, Account Management, Data Analysis, Customer Service, Sr, Software Engineering, Mvc, Ajax, Asp.net, Html, C#, Javascript',\n",
       " 'Qa, Ui/ux, Java Developer, Java Architect, C++/qt, Php, Lamp, Api, J2ee, Java, Soa, Esb, Middleware, Bigdata Achitect, Hadoop Architect, Deep',\n",
       " 'Business Intelligence, Data Warehousing, Data Science, Business Analytics, Customer Support, Business Reporting, Bi',\n",
       " 'Office Administration, Hr Administration, telecalling, client relationship management, Client Acquisition, Sales, Reception, HR, Recruitment, Onboarding, Human',\n",
       " 'Social Media, digital media maketing, seo, smm, smo, sem, Content Wirting, social media marketing, social media manager, digital media marketing manager',\n",
       " 'Oracle Dba, Data Science, Data Warehousing, ETL, Jupyter, Numpy, Data Transformation, Snowflake, Teradata, Python, Data Manipulation, Relational Databases',\n",
       " 'Big Data, Hadoop, Data Analytics, Data Science',\n",
       " 'Data Science, Python, Data Analytics',\n",
       " 'React.js, Data Science, Java, Front End, Business Analytics, Backend, Tableau, Python, Qa Testing, Automation Testing',\n",
       " 'Qlikview, Qlik Sense, Microsoft Azure, Power Bi, Data Science, Machine Learning',\n",
       " 'Telecalling, Client Interaction, Marketing, Research, Web Development, Social Media Marketing, Data Entry Operation, Excel, Ms Office, Invoicing',\n",
       " 'Data Science',\n",
       " 'Corporate Sales, Software Development, Software Sales, Marketing, Creative Designing, Corporate Planning, Senior Management, Crm, Client Relationship',\n",
       " 'Data Analytics, Data Science, Machine Learning, Deep Learning, Nlp, Data Mining, Python, R, Database Administration, Text Mining',\n",
       " 'Data Science, Machine Learning, Python, R, Deep Learning, Big Data, Hadoop',\n",
       " 'Big Data, Data Science, Artificial Intelligence, Hadoop, Ui Development, Php, Freelancing, .Net, Software Testing, Sap, Leadership Hiring',\n",
       " 'Java, Net, Angularjs, Hr, Infrastructure, Management, Project Management, Business Analysis, Data Science, Information Technology, Technology',\n",
       " 'Research, Digital Marketing, Analytics, Software Development, Data Science, Consulting',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Data Analytics',\n",
       " 'Software Architecture, Vp Engineering, Product Management, analytics, Data Science, Node.js, Principal Engineer, Big Data, python, angularjs, React.js',\n",
       " 'Data Science, Hadoop, Rpas, Devops, Python, Aws, Teaching, Big Data',\n",
       " 'Signal Processing, Machine Learning, Neural Networks, Data Science, Predictive Analytics, Time Series Analysis, Data Visualization, Technical Leadership, Data',\n",
       " 'Web Technologies, Project Management, Software Architecture, Data Science, Object Oriented Programming, Computer Science, Electrical Engineering, Architecture',\n",
       " 'Server Administartion, Verilog, Vhdl, Digital Marketing, Market Research, Property Research, Legal, It And Non It Recruitment, Logistics, Supply Chain, Bfsi',\n",
       " 'Data Science, Machine Learning, Deep Learning, Accounting, Statistics',\n",
       " 'Data Analytics, Managed Services, Team Leading, python, Machine Learning, Google Analytics, Dmp, Aws, Campaign Analytics, Digital Campaigns, Audience',\n",
       " 'Ethical Hacking, Security Operations Center, SOC, Managed Services, Data Science, Machine Learning, Artificial Intelligence, Operations Research, Education',\n",
       " 'Data Science, Artificial Intelligence, analytics, Business Intelligence, python, tableau, Power Bi, qlikview, sql, Data Warehousing, Data Visualization',\n",
       " 'Machine Learning, Artificial Intelligence, Data Science, Software Engineering, Software Development, Graduate Engineer Trainee, Fresher, Data Analytics, Java',\n",
       " 'C, C++, Artificial Intelligence, Python, Php, Web Development, Matlab, Data Science, Augmented Reality, C C++',\n",
       " 'Relationship Management, Retail Sales, Private Banking, Mutual Funds, NISM, Equity, Finance, Financial Products, Financial Services, Verbal, Written',\n",
       " 'Data Science, Software Engineering',\n",
       " 'Data Science, Big Data Analytics, Digital Marketing, Content Writing, Ui Development, Database Development, Qa Automation, Python, Project Management',\n",
       " 'Data Science, Recruitment, Salary',\n",
       " 'B.Tech, Tableau, Statistics, R, Analytics, Time Series, Data Science, Business Solutions, SQL, Technical Skills, SSAS, SQL Server, Analysis Services, Qlikview',\n",
       " 'Software Development, Business Intelligence, Big Data Analytics, Database Administration, Data Science, Microsoft Azure, Spark, Cassandra, Object Oriented',\n",
       " 'Data Science, Node.js, Angularjs',\n",
       " 'Data Science, Media Marketing, Resource Planning, Managed Services, Display Advertising, Machine Learning, Python, Etl, Sql',\n",
       " 'Data Analysis, Learning, Data Science, Computer Science, Communication Skills',\n",
       " 'Java, Hadoop, R, Machine Learning, Spark, Flume, Hdfs, Data Mining, Sas, Big, Data Science, Cloudera, Impala, Bigdata',\n",
       " 'Software Development, Core Java, Unit Testing, Customer Experience, Problem Solving, Communication Skills, Mysql, Data Science, Sales Management, Analytics',\n",
       " 'Machine Learning, Data Science, Product Management, New Product, Data Analysis, Computer Vision, Deep Learning, Python, Remote Sensing',\n",
       " 'Not Specified',\n",
       " 'Data Science, Project Management, Power Bi, Business Analysis',\n",
       " 'Business Analysis',\n",
       " 'Data Science, Machine Learning, Big Data Analytics, Spark, Python, R, Networking, Network Engineering, Placement, Training, Sql, Marketing, Mainframes, All',\n",
       " 'Software Professionals, Engineering, Technical Management, Financial Management, Human Resource Management, Banking, Google Adwords, Business Analysis, It',\n",
       " 'Full Stack Developers, Product Manager, Data Science Engineer, Publishers Sales Manager',\n",
       " 'c++, Core Java, kdb, high frequency trading, hft, direct market access, Algorithmic Trading, Quant Development, Market Data, Fpga, Exchange Connectivity',\n",
       " 'Walmart Interra Skeps Expressstores indifi whitehatJr Practo Zylo Doctalk Medtrail',\n",
       " 'Computer Science, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Information Retrieval, Artificial Intelligence, Data Mining',\n",
       " 'Analytics, Machine Learning, Data Science, Etl, Sas, Statistical Analysis, Statistical Modeling, Financial Modelling, Internal Audit, Actuarial, Quality',\n",
       " 'Data Science, Machine Learning, Core Java, Javascript, Mean Stack, Full Satck, Unix, Linux Administration, C, C++, Network Security, .Net, Qa',\n",
       " 'Leadership Hiring, Delivery Leadership, Business Analytics, Data Science, Data Analytics, Data Visualization, Data Modeling, Project Management',\n",
       " 'Web Development, Data Science, Financial Analysis, Front End, Backend',\n",
       " 'Cto, Program Management, Data Science, Artificial Intelligence, Firmware Development, Storage',\n",
       " 'MNC Company',\n",
       " 'c, c++, java, python, Big Data, hadoop, Android Development, bootstrap, jquery, angularjs, Html5, Html, Php, Core Java, Advanced Java, Data Science',\n",
       " 'MNC, CMM Level Companies in India',\n",
       " 'Ai, Data Science, Machine Learning, Deep Learning',\n",
       " 'Python, Big Data, Data Science, Data, R, Learning',\n",
       " 'Data Science, Project Management, Backend',\n",
       " 'Business Analytics, Big Data Analytics, Hadoop, Tableau, Data Science, Business Development, Analytics Sales, Spark, Qlikview, D3.js, Python',\n",
       " 'Information Technology, Machine Learning, Data Science, Artificial Intelligence, Training, Python, Online Training',\n",
       " 'Analytics, Data Science',\n",
       " 'Technical Support, sales, Career Counselling, training, Mechanical Engineering, Computer Science, Information Technology, Hardware Networking, Data Analytics',\n",
       " 'Python, Data Science, Etl, Analytics',\n",
       " 'Corporate Training, It Training, Education, Educational Marketing, Education Industry, Training, Java, .Net, Aws, Hadoop, Android, Salesforce, Salesforce.com',\n",
       " 'Cryptography, Big Data, Data Science, Blockchain',\n",
       " 'Content Writing, research, Software Services, Data Analysis, Analytics, Mechanical Engineering, Computer Science, It Management, Business Development, Business',\n",
       " 'Wireless Communications, 3G/LTE/WiMAX, Broadcom Processors, device drivers in linux, Managerial Experience, Real Time Embedded Engineer',\n",
       " 'Not Specified',\n",
       " 'Data Analytics, Business Intelligence, Software Development, Database Administration, Sales, Inside Sales, Business Analytics, Financial Analysis, Ms Sql',\n",
       " 'Clinical Sas Programming, Sas Programming, Adam',\n",
       " 'Not Specified',\n",
       " 'Big Data, Analytics, Machine Learning, Artificial Intelligence, Business Intelligence, Data Warehousing, Data Mining, Master Data Management, Data Management',\n",
       " 'Analytics, Machine Learning, Big Data Analytics, Predictive Modeling, Advanced Analytics, Statistical Modeling',\n",
       " 'Not Specified',\n",
       " 'Analytics, Mdm, Data Science, Artificial Intelligence, Machine Learning, master data management, Software Development, java, Tibco, Javascript, J2ee, Jsp',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'Training, Java Trainer, Android Trainer, Python Trainer, Bigdata Analyst, Php Trainer, Software Development, Counselling, Career Counselling, Student',\n",
       " 'Not Specified',\n",
       " 'Data Modeling, Data Wrangling, seaborn, eda, python, r, Data Science, ai, Machine Learning, Deep Learning, Neural Networks',\n",
       " 'Data Science, Digital Marketing, Ux Design, Design, Marketing, Development',\n",
       " 'Data Science, Data Engineering, Analytics, New Product Development, Python, Artificial Intelligence, Machine Learning, Solidity, Ui Development, Big Data, Data',\n",
       " 'Freelance Recruitment, Big Data Analytics, Data Science, Data Warehousing, Power Bi, Hive, Pig, Spark, Big Data, SQL, Tensorflow, Pytorch, Machine Learning',\n",
       " 'Data Science',\n",
       " 'Data Science, Artificial Intelligence, analytics, Credit Analysis, Equity Research, Debt Capital Markets, Loan Processing Officers, It Developers',\n",
       " 'Machine Learning, Data Science, Product Management, New Product, Data Analysis, Computer Vision, Deep Learning, Python, Remote Sensing',\n",
       " 'Not Specified',\n",
       " 'Data Science, Project Management, Power Bi, Business Analysis',\n",
       " 'Business Analysis',\n",
       " 'Data Science, Machine Learning, Big Data Analytics, Spark, Python, R, Networking, Network Engineering, Placement, Training, Sql, Marketing, Mainframes, All',\n",
       " 'Software Professionals, Engineering, Technical Management, Financial Management, Human Resource Management, Banking, Google Adwords, Business Analysis, It',\n",
       " 'Full Stack Developers, Product Manager, Data Science Engineer, Publishers Sales Manager',\n",
       " 'c++, Core Java, kdb, high frequency trading, hft, direct market access, Algorithmic Trading, Quant Development, Market Data, Fpga, Exchange Connectivity',\n",
       " 'Walmart Interra Skeps Expressstores indifi whitehatJr Practo Zylo Doctalk Medtrail',\n",
       " 'Computer Science, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Information Retrieval, Artificial Intelligence, Data Mining',\n",
       " 'Analytics, Machine Learning, Data Science, Etl, Sas, Statistical Analysis, Statistical Modeling, Financial Modelling, Internal Audit, Actuarial, Quality',\n",
       " 'Data Science, Machine Learning, Core Java, Javascript, Mean Stack, Full Satck, Unix, Linux Administration, C, C++, Network Security, .Net, Qa',\n",
       " 'Leadership Hiring, Delivery Leadership, Business Analytics, Data Science, Data Analytics, Data Visualization, Data Modeling, Project Management',\n",
       " 'Web Development, Data Science, Financial Analysis, Front End, Backend',\n",
       " 'Cto, Program Management, Data Science, Artificial Intelligence, Firmware Development, Storage',\n",
       " 'MNC Company',\n",
       " 'c, c++, java, python, Big Data, hadoop, Android Development, bootstrap, jquery, angularjs, Html5, Html, Php, Core Java, Advanced Java, Data Science',\n",
       " 'MNC, CMM Level Companies in India',\n",
       " 'Ai, Data Science, Machine Learning, Deep Learning',\n",
       " 'Python, Big Data, Data Science, Data, R, Learning',\n",
       " 'Data Science, Project Management, Backend',\n",
       " 'Business Analytics, Big Data Analytics, Hadoop, Tableau, Data Science, Business Development, Analytics Sales, Spark, Qlikview, D3.js, Python',\n",
       " 'Information Technology, Machine Learning, Data Science, Artificial Intelligence, Training, Python, Online Training',\n",
       " 'Analytics, Data Science',\n",
       " 'Technical Support, sales, Career Counselling, training, Mechanical Engineering, Computer Science, Information Technology, Hardware Networking, Data Analytics',\n",
       " 'Python, Data Science, Etl, Analytics',\n",
       " 'Corporate Training, It Training, Education, Educational Marketing, Education Industry, Training, Java, .Net, Aws, Hadoop, Android, Salesforce, Salesforce.com',\n",
       " 'Cryptography, Big Data, Data Science, Blockchain',\n",
       " 'Content Writing, research, Software Services, Data Analysis, Analytics, Mechanical Engineering, Computer Science, It Management, Business Development, Business',\n",
       " 'Wireless Communications, 3G/LTE/WiMAX, Broadcom Processors, device drivers in linux, Managerial Experience, Real Time Embedded Engineer',\n",
       " 'Not Specified',\n",
       " 'Data Analytics, Business Intelligence, Software Development, Database Administration, Sales, Inside Sales, Business Analytics, Financial Analysis, Ms Sql',\n",
       " 'Clinical Sas Programming, Sas Programming, Adam',\n",
       " 'Not Specified',\n",
       " 'Big Data, Analytics, Machine Learning, Artificial Intelligence, Business Intelligence, Data Warehousing, Data Mining, Master Data Management, Data Management',\n",
       " 'Analytics, Machine Learning, Big Data Analytics, Predictive Modeling, Advanced Analytics, Statistical Modeling',\n",
       " 'Not Specified',\n",
       " 'Analytics, Mdm, Data Science, Artificial Intelligence, Machine Learning, master data management, Software Development, java, Tibco, Javascript, J2ee, Jsp',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'Not Specified',\n",
       " 'Training, Java Trainer, Android Trainer, Python Trainer, Bigdata Analyst, Php Trainer, Software Development, Counselling, Career Counselling, Student',\n",
       " 'Not Specified',\n",
       " 'Data Modeling, Data Wrangling, seaborn, eda, python, r, Data Science, ai, Machine Learning, Deep Learning, Neural Networks',\n",
       " 'Data Science, Digital Marketing, Ux Design, Design, Marketing, Development',\n",
       " 'Data Science, Data Engineering, Analytics, New Product Development, Python, Artificial Intelligence, Machine Learning, Solidity, Ui Development, Big Data, Data',\n",
       " 'Freelance Recruitment, Big Data Analytics, Data Science, Data Warehousing, Power Bi, Hive, Pig, Spark, Big Data, SQL, Tensorflow, Pytorch, Machine Learning',\n",
       " 'Data Science',\n",
       " 'Data Science, Artificial Intelligence, analytics, Credit Analysis, Equity Research, Debt Capital Markets, Loan Processing Officers, It Developers']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skil1=[]\n",
    "for page in range(0,3):  \n",
    "    skil1_tags=driver1.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')  \n",
    "    for i in  skil1_tags:\n",
    "        skil1.append(i.text)\n",
    "    button1=driver1.find_element(By.XPATH,'//button[@class=\"grayBtn\"]')\n",
    "    button1.click()         \n",
    "    time.sleep(3)\n",
    "skil1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc4598a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(skil1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b1c612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classic ASP Developer, Internet Marketing Professional, Data Science SME, Content Writers, SEO Professional, Revenue Professional',\n",
       " '.Net, Java, Data Science, Linux Administration, Sql Server Development, Winforms, Wcf Services, Wpf, Telecom Engineering, Technical Management, Software',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Business Analytics, Deep Learning, statistics, Data Analytics, Data Analysis, support vector machine',\n",
       " 'Mean Stack, javascript, angularjs, mongodb, Web Services, rest, express, Node.js, Big Data, iot, Data Science, Cloud Computing, saas, Aws',\n",
       " 'Hadoop, Spark, Digital Strategy, Data Architecture, Command Center, Cdp, Dmp, Kafka, Data Science, Data Analysis, Big Data Analytics, Real Time Analysis, SQL',\n",
       " 'Analytics, Business Intelligence, Business Analytics, Predictive Modeling, Predictive Analytics, Data Science, Data Analysis, Data Analytics, Big Data, Big',\n",
       " 'Data Science',\n",
       " 'Machine Learning, algorithms, Go Getter, Computer Science, spark, Big Data, hdfs, sql, cassandra, hadoop, python, scala, java, Data Science, Front End',\n",
       " 'Technical Training, Software Development, Presentation Skills, B.tech, M.tech, B.e., mca, msc, Computer Science, freshers, jobs in indore, Data Science, itil',\n",
       " 'Software Development, It Sales, Account Management, Data Analysis, Customer Service, Sr, Software Engineering, Mvc, Ajax, Asp.net, Html, C#, Javascript',\n",
       " 'Qa, Ui/ux, Java Developer, Java Architect, C++/qt, Php, Lamp, Api, J2ee, Java, Soa, Esb, Middleware, Bigdata Achitect, Hadoop Architect, Deep',\n",
       " 'Business Intelligence, Data Warehousing, Data Science, Business Analytics, Customer Support, Business Reporting, Bi',\n",
       " 'Office Administration, Hr Administration, telecalling, client relationship management, Client Acquisition, Sales, Reception, HR, Recruitment, Onboarding, Human',\n",
       " 'Social Media, digital media maketing, seo, smm, smo, sem, Content Wirting, social media marketing, social media manager, digital media marketing manager',\n",
       " 'Oracle Dba, Data Science, Data Warehousing, ETL, Jupyter, Numpy, Data Transformation, Snowflake, Teradata, Python, Data Manipulation, Relational Databases']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill11=skil1[0:15]\n",
    "skill11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6963afe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(skill11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77daa0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/recruiters/aakashharit-1986742?xid=167872015176048100&xp=1',\n",
       " 'https://www.naukri.com/recruiters/shravankumargaddam-353487?xid=167872015176048100&xp=2',\n",
       " 'https://www.naukri.com/recruiters/marsiantech?xid=167872015176048100&xp=3',\n",
       " 'https://www.naukri.com/recruiters/anikagrawal-3647208?xid=167872015176048100&xp=4',\n",
       " 'https://www.naukri.com/recruiters/LXP-DATASCIENCE?xid=167872015176048100&xp=5',\n",
       " 'https://www.naukri.com/recruiters/abhishekyadav-3450244?xid=167872015176048100&xp=6',\n",
       " 'https://www.naukri.com/recruiters/menakav-3213816?xid=167872015176048100&xp=7',\n",
       " 'https://www.naukri.com/recruiters/techvantage?xid=167872015176048100&xp=8',\n",
       " 'https://www.naukri.com/recruiters/asiflucknowi-4331110?xid=167872015176048100&xp=9',\n",
       " 'https://www.naukri.com/recruiters/instafinancials-humanresource?xid=167872015176048100&xp=10',\n",
       " 'https://www.naukri.com/recruiters/kalpana-2078894?xid=167872015176048100&xp=11',\n",
       " 'https://www.naukri.com/recruiters/mubarak-2905498?xid=167872015176048100&xp=12',\n",
       " 'https://www.naukri.com/recruiters/quantmagnum?xid=167872015176048100&xp=13',\n",
       " 'https://www.naukri.com/recruiters/maheshbabuchanna-1803238?xid=167872015176048100&xp=14',\n",
       " 'https://www.naukri.com/recruiters/priyankaakiri-5010064?xid=167872015176048100&xp=15',\n",
       " 'https://www.naukri.com/recruiters/kapildevang-3169734?xid=167872015176048100&xp=16',\n",
       " 'https://www.naukri.com/recruiters/vaishnavikudalkar-5205628?xid=167872015176048100&xp=17',\n",
       " 'https://www.naukri.com/recruiters/sakshichhikara?xid=167872015176048100&xp=18',\n",
       " 'https://www.naukri.com/recruiters/ruchidhote?xid=167872015176048100&xp=19',\n",
       " 'https://www.naukri.com/recruiters/manishayadav-4463916?xid=167872015176048100&xp=20',\n",
       " 'https://www.naukri.com/recruiters/riyarajesh-4375878?xid=167872015176048100&xp=21',\n",
       " 'https://www.naukri.com/recruiters/rashmibhattacharjee-3921774?xid=167872015176048100&xp=22',\n",
       " 'https://www.naukri.com/recruiters/faizankareem-3685102?xid=167872015176048100&xp=23',\n",
       " 'https://www.naukri.com/recruiters/rithikadadwal-3517898?xid=167872015176048100&xp=24',\n",
       " 'https://www.naukri.com/recruiters/ankitshah-21129?xid=167872015176048100&xp=25',\n",
       " 'https://www.naukri.com/recruiters/shaunrao-3020604?xid=167872015176048100&xp=26',\n",
       " 'https://www.naukri.com/recruiters/deeparchisharma?xid=167872015176048100&xp=27',\n",
       " 'https://www.naukri.com/recruiters/azaharshaikh-companyrecruiter?xid=167872015176048100&xp=28',\n",
       " 'https://www.naukri.com/recruiters/manas-3159036?xid=167872015176048100&xp=29',\n",
       " 'https://www.naukri.com/recruiters/kumar-3378892?xid=167872015176048100&xp=30',\n",
       " 'https://www.naukri.com/recruiters/sunilvedula-3392046?xid=167872015176048100&xp=31',\n",
       " 'https://www.naukri.com/recruiters/rajatkumar-3295096?xid=167872015176048100&xp=32',\n",
       " 'https://www.naukri.com/recruiters/dhruvdevdubey?xid=167872015176048100&xp=33',\n",
       " 'https://www.naukri.com/recruiters/avnishmishra-5310575?xid=167872015176048100&xp=34',\n",
       " 'https://www.naukri.com/recruiters/jayanthn-3081850?xid=167872015176048100&xp=35',\n",
       " 'https://www.naukri.com/recruiters/nikithapalaparthi-5172698?xid=167872015176048100&xp=36',\n",
       " 'https://www.naukri.com/recruiters/priyakhare-4894796?xid=167872015176048100&xp=37',\n",
       " 'https://www.naukri.com/recruiters/amitsharma-4238940?xid=167872015176048100&xp=38',\n",
       " 'https://www.naukri.com/recruiters/deepali002g?xid=167872015176048100&xp=39',\n",
       " 'https://www.naukri.com/recruiters/shashikantchaudhary-4164854?xid=167872015176048100&xp=40',\n",
       " 'https://www.naukri.com/recruiters/brad-4068508?xid=167872015176048100&xp=41',\n",
       " 'https://www.naukri.com/recruiters/rutujapawar?xid=167872015176048100&xp=42',\n",
       " 'https://www.naukri.com/recruiters/madhusudhansridhar-2705338?xid=167872015176048100&xp=43',\n",
       " 'https://www.naukri.com/recruiters/ankitsinha-3398798?xid=167872015176048100&xp=44',\n",
       " 'https://www.naukri.com/recruiters/gauravchouhan?xid=167872015176048100&xp=45',\n",
       " 'https://www.naukri.com/recruiters/impel?xid=167872015176048100&xp=46',\n",
       " 'https://www.naukri.com/recruiters/ashwini-3434922?xid=167872015176048100&xp=47',\n",
       " 'https://www.naukri.com/recruiters/balajikolli-2870676?xid=167872015176048100&xp=48',\n",
       " 'https://www.naukri.com/recruiters/rajaninagaraj-3387578?xid=167872015176048100&xp=49',\n",
       " 'https://www.naukri.com/recruiters/rohitkumar-3277680?xid=167872015176048100&xp=50',\n",
       " 'https://www.naukri.com/recruiters/amirchowdhury-2925314?xid=167872016511402400&xp=1',\n",
       " 'https://www.naukri.com/recruiters/shailajan-3766340?xid=167872016511402400&xp=2',\n",
       " 'https://www.naukri.com/recruiters/shahulhameedaa-5505381?xid=167872016511402400&xp=3',\n",
       " 'https://www.naukri.com/recruiters/vidyabhushansingh?xid=167872016511402400&xp=4',\n",
       " 'https://www.naukri.com/recruiters/sreedhar-3824102?xid=167872016511402400&xp=5',\n",
       " 'https://www.naukri.com/recruiters/sunnysharma-mumbai?xid=167872016511402400&xp=6',\n",
       " 'https://www.naukri.com/recruiters/lamasagar?xid=167872016511402400&xp=7',\n",
       " 'https://www.naukri.com/recruiters/danielvaz?xid=167872016511402400&xp=8',\n",
       " 'https://www.naukri.com/recruiters/priyaranjanmishra-4206690?xid=167872016511402400&xp=9',\n",
       " 'https://www.naukri.com/recruiters/drsprasannadevi-3943244?xid=167872016511402400&xp=10',\n",
       " 'https://www.naukri.com/recruiters/rajni-1291486?xid=167872016511402400&xp=11',\n",
       " 'https://www.naukri.com/recruiters/preetim-2405036?xid=167872016511402400&xp=12',\n",
       " 'https://www.naukri.com/recruiters/seniorrecruiter-3792750?xid=167872016511402400&xp=13',\n",
       " 'https://www.naukri.com/recruiters/sampatel-4406340?xid=167872016511402400&xp=14',\n",
       " 'https://www.naukri.com/recruiters/vivekkapadia-4242620?xid=167872016511402400&xp=15',\n",
       " 'https://www.naukri.com/recruiters/qcheck?xid=167872016511402400&xp=16',\n",
       " 'https://www.naukri.com/recruiters/aptechcomputereducation-4008860?xid=167872016511402400&xp=17',\n",
       " 'https://www.naukri.com/recruiters/macherlasureshkumar-3441132?xid=167872016511402400&xp=18',\n",
       " 'https://www.naukri.com/recruiters/digitalai?xid=167872016511402400&xp=19',\n",
       " 'https://www.naukri.com/recruiters/gujaratitsolution-3185500?xid=167872016511402400&xp=20',\n",
       " 'https://www.naukri.com/recruiters/santhoshnagaiah-4385586?xid=167872016511402400&xp=21',\n",
       " 'https://www.naukri.com/recruiters/ranjitr?xid=167872016511402400&xp=22',\n",
       " 'https://www.naukri.com/recruiters/prashanth-4378786?xid=167872016511402400&xp=23',\n",
       " 'https://www.naukri.com/recruiters/arunimdas-4348820?xid=167872016511402400&xp=24',\n",
       " 'https://www.naukri.com/recruiters/kogila-4263502?xid=167872016511402400&xp=25',\n",
       " 'https://www.naukri.com/recruiters/gurpreetkhera-3393498?xid=167872016511402400&xp=26',\n",
       " 'https://www.naukri.com/recruiters/NareshIT?xid=167872016511402400&xp=27',\n",
       " 'https://www.naukri.com/recruiters/rajpaltyagi-3359590?xid=167872016511402400&xp=28',\n",
       " 'https://www.naukri.com/recruiters/UrviKumar-AugmentSystems?xid=167872016511402400&xp=29',\n",
       " 'https://www.naukri.com/recruiters/vikrampethe-2305540?xid=167872016511402400&xp=30',\n",
       " 'https://www.naukri.com/recruiters/umamaheswari-2460264?xid=167872016511402400&xp=31',\n",
       " 'https://www.naukri.com/recruiters/instafinancials?xid=167872016511402400&xp=32',\n",
       " 'https://www.naukri.com/recruiters/shyampasumarthy-2127712?xid=167872016511402400&xp=33',\n",
       " 'https://www.naukri.com/recruiters/akashkulkarni-4360118?xid=167872016511402400&xp=34',\n",
       " 'https://www.naukri.com/recruiters/anandh-3356608?xid=167872016511402400&xp=35',\n",
       " 'https://www.naukri.com/recruiters/leenanothani-3739650?xid=167872016511402400&xp=36',\n",
       " 'https://www.naukri.com/recruiters/sanchitgarg-3173638?xid=167872016511402400&xp=37',\n",
       " 'https://www.naukri.com/recruiters/businessbrio?xid=167872016511402400&xp=38',\n",
       " 'https://www.naukri.com/recruiters/mamtarawat-3793596?xid=167872016511402400&xp=39',\n",
       " 'https://www.naukri.com/recruiters/sandeepseth-2493028?xid=167872016511402400&xp=40',\n",
       " 'https://www.naukri.com/recruiters/mamtarawat-3786916?xid=167872016511402400&xp=41',\n",
       " 'https://www.naukri.com/recruiters/pradeep-3368096?xid=167872016511402400&xp=42',\n",
       " 'https://www.naukri.com/recruiters/sorav-907707?xid=167872016511402400&xp=43',\n",
       " 'https://www.naukri.com/recruiters/HRAlgoSquare?xid=167872016511402400&xp=44',\n",
       " 'https://www.naukri.com/recruiters/narasimha-5070962?xid=167872016511402400&xp=45',\n",
       " 'https://www.naukri.com/recruiters/venkatc?xid=167872016511402400&xp=46',\n",
       " 'https://www.naukri.com/recruiters/srinivasanalagurajan?xid=167872016511402400&xp=47',\n",
       " 'https://www.naukri.com/recruiters/aneela?xid=167872016511402400&xp=48',\n",
       " 'https://www.naukri.com/recruiters/priyankabalodi?xid=167872016511402400&xp=49',\n",
       " 'https://www.naukri.com/recruiters/snomvi-5201450?xid=167872016511402400&xp=50',\n",
       " 'https://www.naukri.com/recruiters/aakashharit-1986742?xid=167872017149805000&xp=1',\n",
       " 'https://www.naukri.com/recruiters/shravankumargaddam-353487?xid=167872017149805000&xp=2',\n",
       " 'https://www.naukri.com/recruiters/marsiantech?xid=167872017149805000&xp=3',\n",
       " 'https://www.naukri.com/recruiters/anikagrawal-3647208?xid=167872017149805000&xp=4',\n",
       " 'https://www.naukri.com/recruiters/LXP-DATASCIENCE?xid=167872017149805000&xp=5',\n",
       " 'https://www.naukri.com/recruiters/abhishekyadav-3450244?xid=167872017149805000&xp=6',\n",
       " 'https://www.naukri.com/recruiters/menakav-3213816?xid=167872017149805000&xp=7',\n",
       " 'https://www.naukri.com/recruiters/techvantage?xid=167872017149805000&xp=8',\n",
       " 'https://www.naukri.com/recruiters/asiflucknowi-4331110?xid=167872017149805000&xp=9',\n",
       " 'https://www.naukri.com/recruiters/instafinancials-humanresource?xid=167872017149805000&xp=10',\n",
       " 'https://www.naukri.com/recruiters/kalpana-2078894?xid=167872017149805000&xp=11',\n",
       " 'https://www.naukri.com/recruiters/mubarak-2905498?xid=167872017149805000&xp=12',\n",
       " 'https://www.naukri.com/recruiters/quantmagnum?xid=167872017149805000&xp=13',\n",
       " 'https://www.naukri.com/recruiters/maheshbabuchanna-1803238?xid=167872017149805000&xp=14',\n",
       " 'https://www.naukri.com/recruiters/priyankaakiri-5010064?xid=167872017149805000&xp=15',\n",
       " 'https://www.naukri.com/recruiters/kapildevang-3169734?xid=167872017149805000&xp=16',\n",
       " 'https://www.naukri.com/recruiters/vaishnavikudalkar-5205628?xid=167872017149805000&xp=17',\n",
       " 'https://www.naukri.com/recruiters/sakshichhikara?xid=167872017149805000&xp=18',\n",
       " 'https://www.naukri.com/recruiters/ruchidhote?xid=167872017149805000&xp=19',\n",
       " 'https://www.naukri.com/recruiters/manishayadav-4463916?xid=167872017149805000&xp=20',\n",
       " 'https://www.naukri.com/recruiters/riyarajesh-4375878?xid=167872017149805000&xp=21',\n",
       " 'https://www.naukri.com/recruiters/rashmibhattacharjee-3921774?xid=167872017149805000&xp=22',\n",
       " 'https://www.naukri.com/recruiters/faizankareem-3685102?xid=167872017149805000&xp=23',\n",
       " 'https://www.naukri.com/recruiters/rithikadadwal-3517898?xid=167872017149805000&xp=24',\n",
       " 'https://www.naukri.com/recruiters/ankitshah-21129?xid=167872017149805000&xp=25',\n",
       " 'https://www.naukri.com/recruiters/shaunrao-3020604?xid=167872017149805000&xp=26',\n",
       " 'https://www.naukri.com/recruiters/deeparchisharma?xid=167872017149805000&xp=27',\n",
       " 'https://www.naukri.com/recruiters/azaharshaikh-companyrecruiter?xid=167872017149805000&xp=28',\n",
       " 'https://www.naukri.com/recruiters/manas-3159036?xid=167872017149805000&xp=29',\n",
       " 'https://www.naukri.com/recruiters/kumar-3378892?xid=167872017149805000&xp=30',\n",
       " 'https://www.naukri.com/recruiters/sunilvedula-3392046?xid=167872017149805000&xp=31',\n",
       " 'https://www.naukri.com/recruiters/rajatkumar-3295096?xid=167872017149805000&xp=32',\n",
       " 'https://www.naukri.com/recruiters/dhruvdevdubey?xid=167872017149805000&xp=33',\n",
       " 'https://www.naukri.com/recruiters/avnishmishra-5310575?xid=167872017149805000&xp=34',\n",
       " 'https://www.naukri.com/recruiters/jayanthn-3081850?xid=167872017149805000&xp=35',\n",
       " 'https://www.naukri.com/recruiters/nikithapalaparthi-5172698?xid=167872017149805000&xp=36',\n",
       " 'https://www.naukri.com/recruiters/priyakhare-4894796?xid=167872017149805000&xp=37',\n",
       " 'https://www.naukri.com/recruiters/amitsharma-4238940?xid=167872017149805000&xp=38',\n",
       " 'https://www.naukri.com/recruiters/deepali002g?xid=167872017149805000&xp=39',\n",
       " 'https://www.naukri.com/recruiters/shashikantchaudhary-4164854?xid=167872017149805000&xp=40',\n",
       " 'https://www.naukri.com/recruiters/brad-4068508?xid=167872017149805000&xp=41',\n",
       " 'https://www.naukri.com/recruiters/rutujapawar?xid=167872017149805000&xp=42',\n",
       " 'https://www.naukri.com/recruiters/madhusudhansridhar-2705338?xid=167872017149805000&xp=43',\n",
       " 'https://www.naukri.com/recruiters/ankitsinha-3398798?xid=167872017149805000&xp=44',\n",
       " 'https://www.naukri.com/recruiters/gauravchouhan?xid=167872017149805000&xp=45',\n",
       " 'https://www.naukri.com/recruiters/impel?xid=167872017149805000&xp=46',\n",
       " 'https://www.naukri.com/recruiters/ashwini-3434922?xid=167872017149805000&xp=47',\n",
       " 'https://www.naukri.com/recruiters/balajikolli-2870676?xid=167872017149805000&xp=48',\n",
       " 'https://www.naukri.com/recruiters/rajaninagaraj-3387578?xid=167872017149805000&xp=49',\n",
       " 'https://www.naukri.com/recruiters/rohitkumar-3277680?xid=167872017149805000&xp=50']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1=[]\n",
    "for page in range (0,3):\n",
    "    url=driver1.find_elements(By.XPATH,'//a[@class=\"ellipsis\"][1]')\n",
    "    for i in url:\n",
    "        url1.append(i.get_attribute('href'))\n",
    "    button1=driver1.find_element(By.XPATH,'//button[@class=\"grayBtn\"]')\n",
    "    button1.click()\n",
    "    time.sleep(3)\n",
    "url1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe20e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(url1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76e69e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aakash Harit',\n",
       " 'shravan Kumar Gaddam',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'Anik Agrawal',\n",
       " 'subhas patel',\n",
       " 'Abhishek - Only Analytics Hiring - India and APAC',\n",
       " 'Institute for Financial Management and Research',\n",
       " 'Balu Ramesh',\n",
       " 'Asif Lucknowi',\n",
       " 'InstaFinancials',\n",
       " 'Kalpana Dumpala',\n",
       " 'Mubarak',\n",
       " 'Kushal Rastogi',\n",
       " 'Mahesh Babu Channa',\n",
       " 'Priyanka Akiri']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name1=[]\n",
    "for i in url1[0:15]:\n",
    "    driver1.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        name1_tag=driver1.find_element(By.XPATH,'//h1[@class=\"fl ellipsis wLimit hd\"]')\n",
    "        name1.append(name1_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        name1.append('-')\n",
    "name1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae8afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HR Manager',\n",
       " 'Company Recruiter',\n",
       " 'Company HR',\n",
       " 'Company Recruiter',\n",
       " 'Founder & CEO',\n",
       " 'Recruitment - Lead Consultant',\n",
       " 'Programme Manager',\n",
       " 'HR Administrator',\n",
       " 'Director',\n",
       " 'Human Resource',\n",
       " 'Executive Hiring',\n",
       " 'Company HR',\n",
       " 'Company HR',\n",
       " 'HR Team Lead',\n",
       " 'HR Manager']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des1=[]\n",
    "for i in url1[0:15]:\n",
    "    driver1.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        des1_tag=driver1.find_element(By.XPATH,'//div[@class=\"ellipsis\"]')\n",
    "        des1.append(des1_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        des1.append('-')\n",
    "des1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b6bac11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Network',\n",
       " 'Shore Infotech India Pvt. Ltd',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'Enerlytics Software Solutions Pvt Ltd',\n",
       " 'LibraryXProject',\n",
       " 'Apidel Technologies Division of Transpower',\n",
       " 'IFMR',\n",
       " 'Techvantage Systems Pvt Ltd',\n",
       " 'Weupskill- Live Wire India',\n",
       " 'CBL Data Science Private Limited',\n",
       " 'Innominds Software',\n",
       " 'MoneyTap',\n",
       " 'QuantMagnum Technologies Pvt. Ltd.',\n",
       " 'SocialPrachar.com',\n",
       " 'Infinitive Software Solutions']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com1=[]\n",
    "for i in url1[0:15]:\n",
    "    driver1.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        com1_tag=driver1.find_element(By.XPATH,'//div[@class=\"rFrame fl infoWrapper\"]/div[4]')\n",
    "        com1.append(com1_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        com1.append('-')\n",
    "com1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96fb7de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Ahmedabad',\n",
       " 'UK - (london)',\n",
       " 'Vadodara / Baroda',\n",
       " 'Chennai',\n",
       " 'Trivandrum',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Hyderabad']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc1=[]\n",
    "for i in url1[0:15]:\n",
    "    driver1.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        loc1_tag=driver1.find_element(By.XPATH,'//div[@class=\"rFrame fl infoWrapper\"]/div[5]')\n",
    "        loc1.append(loc1_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        loc1.append('-')\n",
    "loc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a045c5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESIGNATION</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>SKILL THEY HIRE FOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and APAC</td>\n",
       "      <td>Recruitment - Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Research</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Trivandrum</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 NAME  \\\n",
       "0                                        Aakash Harit   \n",
       "1                                shravan Kumar Gaddam   \n",
       "2                            MARSIAN Technologies LLP   \n",
       "3                                        Anik Agrawal   \n",
       "4                                        subhas patel   \n",
       "5   Abhishek - Only Analytics Hiring - India and APAC   \n",
       "6     Institute for Financial Management and Research   \n",
       "7                                         Balu Ramesh   \n",
       "8                                       Asif Lucknowi   \n",
       "9                                     InstaFinancials   \n",
       "10                                    Kalpana Dumpala   \n",
       "11                                            Mubarak   \n",
       "12                                     Kushal Rastogi   \n",
       "13                                 Mahesh Babu Channa   \n",
       "14                                     Priyanka Akiri   \n",
       "\n",
       "                      DESIGNATION                                     COMPANY  \\\n",
       "0                      HR Manager                        Data Science Network   \n",
       "1               Company Recruiter               Shore Infotech India Pvt. Ltd   \n",
       "2                      Company HR                    MARSIAN Technologies LLP   \n",
       "3               Company Recruiter       Enerlytics Software Solutions Pvt Ltd   \n",
       "4                   Founder & CEO                             LibraryXProject   \n",
       "5   Recruitment - Lead Consultant  Apidel Technologies Division of Transpower   \n",
       "6               Programme Manager                                        IFMR   \n",
       "7                HR Administrator                 Techvantage Systems Pvt Ltd   \n",
       "8                        Director                  Weupskill- Live Wire India   \n",
       "9                  Human Resource            CBL Data Science Private Limited   \n",
       "10               Executive Hiring                          Innominds Software   \n",
       "11                     Company HR                                    MoneyTap   \n",
       "12                     Company HR          QuantMagnum Technologies Pvt. Ltd.   \n",
       "13                   HR Team Lead                           SocialPrachar.com   \n",
       "14                     HR Manager               Infinitive Software Solutions   \n",
       "\n",
       "                    LOCATION  \\\n",
       "0                      Delhi   \n",
       "1   Hyderabad / Secunderabad   \n",
       "2                       Pune   \n",
       "3                  Ahmedabad   \n",
       "4              UK - (london)   \n",
       "5          Vadodara / Baroda   \n",
       "6                    Chennai   \n",
       "7                 Trivandrum   \n",
       "8                     Indore   \n",
       "9      Bengaluru / Bangalore   \n",
       "10  Hyderabad / Secunderabad   \n",
       "11     Bengaluru / Bangalore   \n",
       "12                    Mumbai   \n",
       "13  Hyderabad / Secunderabad   \n",
       "14                 Hyderabad   \n",
       "\n",
       "                                  SKILL THEY HIRE FOR  \n",
       "0   Classic ASP Developer, Internet Marketing Prof...  \n",
       "1   .Net, Java, Data Science, Linux Administration...  \n",
       "2   Data Science, Artificial Intelligence, Machine...  \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "5   Analytics, Business Intelligence, Business Ana...  \n",
       "6                                        Data Science  \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...  \n",
       "8   Technical Training, Software Development, Pres...  \n",
       "9   Software Development, It Sales, Account Manage...  \n",
       "10  Qa, Ui/ux, Java Developer, Java Architect, C++...  \n",
       "11  Business Intelligence, Data Warehousing, Data ...  \n",
       "12  Office Administration, Hr Administration, tele...  \n",
       "13  Social Media, digital media maketing, seo, smm...  \n",
       "14  Oracle Dba, Data Science, Data Warehousing, ET...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame({'NAME':name1,'DESIGNATION':des1,'COMPANY':com1,'LOCATION':loc1,'SKILL THEY HIRE FOR':skill11})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26718b52",
   "metadata": {},
   "source": [
    "# PROBLEM NO.1 - MOST VIEWED VIDEOS IN YOUTUBE FROM WIKIPEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f911ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fa9e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2=webdriver.Chrome(r\"chromedriver.exe\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17bc301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4172dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank2=[]\n",
    "rank2tag=driver2.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "for i in rank2tag:\n",
    "    rank2.append(i.text)\n",
    "rank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84f8b6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[4]',\n",
       " '\"Despacito\"[7]',\n",
       " '\"Johny Johny Yes Papa\"[14]',\n",
       " '\"Bath Song\"[15]',\n",
       " '\"Shape of You\"[16]',\n",
       " '\"See You Again\"[18]',\n",
       " '\"Phonics Song with Two Words\"[23]',\n",
       " '\"Wheels on the Bus\"[24]',\n",
       " '\"Uptown Funk\"[25]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[26]',\n",
       " '\"Gangnam Style\"[27]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[32]',\n",
       " '\"Dame Tu Cosita\"[33]',\n",
       " '\"Sugar\"[34]',\n",
       " '\"Axel F\"[35]',\n",
       " '\"Roar\"[36]',\n",
       " '\"Counting Stars\"[37]',\n",
       " '\"Sorry\"[38]',\n",
       " '\"Thinking Out Loud\"[39]',\n",
       " '\"Baa Baa Black Sheep\"[40]',\n",
       " '\"Waka Waka (This Time for Africa)\"[41]',\n",
       " '\"Dark Horse\"[42]',\n",
       " '\"Faded\"[43]',\n",
       " '\"Let Her Go\"[44]',\n",
       " '\"Girls Like You\"[45]',\n",
       " '\"Perfect\"[46]',\n",
       " '\"Bailando\"[47]',\n",
       " '\"Lean On\"[48]',\n",
       " '\"Lakdi Ki Kathi\"[49]',\n",
       " '\"Humpty the train on a fruits ride\"[50]']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2=[]\n",
    "name2tag=driver2.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "for i in name2tag:\n",
    "    name2.append(i.text)\n",
    "name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a31fabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'ChuChu TV',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Psy',\n",
       " 'Get Movies',\n",
       " 'El Chombo',\n",
       " 'Maroon 5',\n",
       " 'Crazy Frog',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Justin Bieber',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Shakira',\n",
       " 'Katy Perry',\n",
       " 'Alan Walker',\n",
       " 'Passenger',\n",
       " 'Maroon 5',\n",
       " 'Ed Sheeran',\n",
       " 'Enrique Iglesias',\n",
       " 'Major Lazer',\n",
       " 'Jingle Toons',\n",
       " 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art2=[]\n",
    "art2tag=driver2.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')\n",
    "for i in art2tag:\n",
    "    art2.append(i.text)\n",
    "art2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af9f010e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12.37',\n",
       " '8.09',\n",
       " '6.63',\n",
       " '6.03',\n",
       " '5.92',\n",
       " '5.79',\n",
       " '5.17',\n",
       " '4.95',\n",
       " '4.84',\n",
       " '4.83',\n",
       " '4.70',\n",
       " '4.53',\n",
       " '4.24',\n",
       " '3.82',\n",
       " '3.76',\n",
       " '3.73',\n",
       " '3.73',\n",
       " '3.63',\n",
       " '3.55',\n",
       " '3.51',\n",
       " '3.48',\n",
       " '3.45',\n",
       " '3.41',\n",
       " '3.38',\n",
       " '3.37',\n",
       " '3.37',\n",
       " '3.34',\n",
       " '3.33',\n",
       " '3.32',\n",
       " '3.31']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2=[]\n",
    "v2tag=driver2.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]')\n",
    "for i in v2tag:\n",
    "    v2.append(i.text)\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49705c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'May 2, 2018',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'March 6, 2014',\n",
       " 'May 24, 2018',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'January 14, 2015',\n",
       " 'June 16, 2009',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'October 22, 2015',\n",
       " 'October 7, 2014',\n",
       " 'June 25, 2018',\n",
       " 'June 4, 2010',\n",
       " 'February 20, 2014',\n",
       " 'December 3, 2015',\n",
       " 'July 25, 2012',\n",
       " 'May 31, 2018',\n",
       " 'November 9, 2017',\n",
       " 'April 11, 2014',\n",
       " 'March 22, 2015',\n",
       " 'June 14, 2018',\n",
       " 'January 26, 2018']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ud2=[]\n",
    "ud2tag=driver2.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')\n",
    "for i in ud2tag:\n",
    "    ud2.append(i.text)\n",
    "ud2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22f6c45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ARTIST</th>\n",
       "      <th>UPLOAD DATE</th>\n",
       "      <th>VIEWS IN BILLIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[24]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[25]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Axel F\"[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[36]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[37]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[41]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"[45]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[49]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[50]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                                             NAME  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                          \"Wheels on the Bus\"[24]   \n",
       "8    9.                                \"Uptown Funk\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                     \"Axel F\"[35]   \n",
       "15  16.                                       \"Roar\"[36]   \n",
       "16  17.                             \"Counting Stars\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
       "21  22.                                 \"Dark Horse\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.                             \"Girls Like You\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.                             \"Lakdi Ki Kathi\"[49]   \n",
       "29  30.          \"Humpty the train on a fruits ride\"[50]   \n",
       "\n",
       "                                           ARTIST        UPLOAD DATE  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "8                                     Mark Ronson  November 19, 2014   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                       Maroon 5   January 14, 2015   \n",
       "14                                     Crazy Frog      June 16, 2009   \n",
       "15                                     Katy Perry  September 5, 2013   \n",
       "16                                    OneRepublic       May 31, 2013   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                                     Ed Sheeran    October 7, 2014   \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "20                                        Shakira       June 4, 2010   \n",
       "21                                     Katy Perry  February 20, 2014   \n",
       "22                                    Alan Walker   December 3, 2015   \n",
       "23                                      Passenger      July 25, 2012   \n",
       "24                                       Maroon 5       May 31, 2018   \n",
       "25                                     Ed Sheeran   November 9, 2017   \n",
       "26                               Enrique Iglesias     April 11, 2014   \n",
       "27                                    Major Lazer     March 22, 2015   \n",
       "28                                   Jingle Toons      June 14, 2018   \n",
       "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "\n",
       "   VIEWS IN BILLIONS  \n",
       "0              12.37  \n",
       "1               8.09  \n",
       "2               6.63  \n",
       "3               6.03  \n",
       "4               5.92  \n",
       "5               5.79  \n",
       "6               5.17  \n",
       "7               4.95  \n",
       "8               4.84  \n",
       "9               4.83  \n",
       "10              4.70  \n",
       "11              4.53  \n",
       "12              4.24  \n",
       "13              3.82  \n",
       "14              3.76  \n",
       "15              3.73  \n",
       "16              3.73  \n",
       "17              3.63  \n",
       "18              3.55  \n",
       "19              3.51  \n",
       "20              3.48  \n",
       "21              3.45  \n",
       "22              3.41  \n",
       "23              3.38  \n",
       "24              3.37  \n",
       "25              3.37  \n",
       "26              3.34  \n",
       "27              3.33  \n",
       "28              3.32  \n",
       "29              3.31  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame({'RANK':rank2,'NAME':name2,'ARTIST':art2,'UPLOAD DATE':ud2,'VIEWS IN BILLIONS':v2})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77813a4f",
   "metadata": {},
   "source": [
    "# PROBLEM NO.3 - STATE WISE GDP OF INDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbc64eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0bbdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b196a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7add8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search3=driver3.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\")\n",
    "search3.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52b47d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "search33=driver3.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/div/a[3]\")\n",
    "search33.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff09d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "search333=driver3.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "search333.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2adbb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank3=[]\n",
    "rank3tag=driver3.find_elements(By.XPATH,'//div[@class=\"fwidth\"][3]/div/div/table/tbody/tr/td[1]')\n",
    "for i in rank3tag:\n",
    "    rank3.append(i.text)\n",
    "rank3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0baaa6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state3=[]\n",
    "state3tag=driver3.find_elements(By.XPATH,'//div[@class=\"fwidth\"][3]/div/div/table/tbody/tr/td[2]')\n",
    "for i in state3tag:\n",
    "    state3.append(i.text)\n",
    "state3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0517c33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,845,853',\n",
       " '1,687,818',\n",
       " '-',\n",
       " '1,631,977',\n",
       " '1,253,832',\n",
       " '1,020,989',\n",
       " '972,782',\n",
       " '969,604',\n",
       " '906,672',\n",
       " '-',\n",
       " '856,112',\n",
       " '831,610',\n",
       " '611,804',\n",
       " '574,760',\n",
       " '521,275',\n",
       " '-',\n",
       " '329,180',\n",
       " '328,598',\n",
       " '-',\n",
       " '-',\n",
       " '165,472',\n",
       " '80,449',\n",
       " '55,984',\n",
       " '-',\n",
       " '38,253',\n",
       " '36,572',\n",
       " '32,496',\n",
       " '31,790',\n",
       " '-',\n",
       " '-',\n",
       " '26,503',\n",
       " '-']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g19203=[]\n",
    "g19203tag=driver3.find_elements(By.XPATH,'//div[@class=\"fwidth\"][3]/div/div/table/tbody/tr/td[3]')\n",
    "for i in g19203tag:\n",
    "    g19203.append(i.text)\n",
    "g19203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ed2150d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g18193=[]\n",
    "g18193tag=driver3.find_elements(By.XPATH,'//div[@class=\"fwidth\"][3]/div/div/table/tbody/tr/td[4]')\n",
    "for i in g18193tag:\n",
    "    g18193.append(i.text)\n",
    "g18193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b36e649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share3=[]\n",
    "share3tag=driver3.find_elements(By.XPATH,'//div[@class=\"fwidth\"][3]/div/div/table/tbody/tr/td[5]')\n",
    "for i in share3tag:\n",
    "    share3.append(i.text)\n",
    "share3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f86f547b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp3=[]\n",
    "gdp3tag=driver3.find_elements(By.XPATH,'//div[@class=\"fwidth\"][3]/div/div/table/tbody/tr/td[6]')\n",
    "for i in gdp3tag:\n",
    "    gdp3.append(i.text)\n",
    "gdp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8b6d5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP(18-19) AT CURRENT PRICES in Cr INR</th>\n",
       "      <th>GSDP(19-20) AT CURRENT PRICES in Cr INR</th>\n",
       "      <th>SHARE</th>\n",
       "      <th>GDP ($ BILLION)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE GSDP(18-19) AT CURRENT PRICES in Cr INR  \\\n",
       "0     1                Maharashtra                               2,632,792   \n",
       "1     2                 Tamil Nadu                               1,630,208   \n",
       "2     3              Uttar Pradesh                               1,584,764   \n",
       "3     4                    Gujarat                               1,502,899   \n",
       "4     5                  Karnataka                               1,493,127   \n",
       "5     6                West Bengal                               1,089,898   \n",
       "6     7                  Rajasthan                                 942,586   \n",
       "7     8             Andhra Pradesh                                 862,957   \n",
       "8     9                  Telangana                                 861,031   \n",
       "9    10             Madhya Pradesh                                 809,592   \n",
       "10   11                     Kerala                                 781,653   \n",
       "11   12                      Delhi                                 774,870   \n",
       "12   13                    Haryana                                 734,163   \n",
       "13   14                      Bihar                                 530,363   \n",
       "14   15                     Punjab                                 526,376   \n",
       "15   16                     Odisha                                 487,805   \n",
       "16   17                      Assam                                 315,881   \n",
       "17   18               Chhattisgarh                                 304,063   \n",
       "18   19                  Jharkhand                                 297,204   \n",
       "19   20                Uttarakhand                                 245,895   \n",
       "20   21            Jammu & Kashmir                                 155,956   \n",
       "21   22           Himachal Pradesh                                 153,845   \n",
       "22   23                        Goa                                  73,170   \n",
       "23   24                    Tripura                                  49,845   \n",
       "24   25                 Chandigarh                                  42,114   \n",
       "25   26                 Puducherry                                  34,433   \n",
       "26   27                  Meghalaya                                  33,481   \n",
       "27   28                     Sikkim                                  28,723   \n",
       "28   29                    Manipur                                  27,870   \n",
       "29   30                   Nagaland                                  27,283   \n",
       "30   31          Arunachal Pradesh                                  24,603   \n",
       "31   32                    Mizoram                                  22,287   \n",
       "32   33  Andaman & Nicobar Islands                                       -   \n",
       "\n",
       "   GSDP(19-20) AT CURRENT PRICES in Cr INR   SHARE GDP ($ BILLION)  \n",
       "0                                        -  13.94%         399.921  \n",
       "1                                1,845,853   8.63%         247.629  \n",
       "2                                1,687,818   8.39%         240.726  \n",
       "3                                        -   7.96%         228.290  \n",
       "4                                1,631,977   7.91%         226.806  \n",
       "5                                1,253,832   5.77%         165.556  \n",
       "6                                1,020,989   4.99%         143.179  \n",
       "7                                  972,782   4.57%         131.083  \n",
       "8                                  969,604   4.56%         130.791  \n",
       "9                                  906,672   4.29%         122.977  \n",
       "10                                       -   4.14%         118.733  \n",
       "11                                 856,112   4.10%         117.703  \n",
       "12                                 831,610   3.89%         111.519  \n",
       "13                                 611,804   2.81%          80.562  \n",
       "14                                 574,760   2.79%          79.957  \n",
       "15                                 521,275   2.58%          74.098  \n",
       "16                                       -   1.67%          47.982  \n",
       "17                                 329,180   1.61%          46.187  \n",
       "18                                 328,598   1.57%          45.145  \n",
       "19                                       -   1.30%          37.351  \n",
       "20                                       -   0.83%          23.690  \n",
       "21                                 165,472   0.81%          23.369  \n",
       "22                                  80,449   0.39%          11.115  \n",
       "23                                  55,984   0.26%           7.571  \n",
       "24                                       -   0.22%           6.397  \n",
       "25                                  38,253   0.18%           5.230  \n",
       "26                                  36,572   0.18%           5.086  \n",
       "27                                  32,496   0.15%           4.363  \n",
       "28                                  31,790   0.15%           4.233  \n",
       "29                                       -   0.14%           4.144  \n",
       "30                                       -   0.13%           3.737  \n",
       "31                                  26,503   0.12%           3.385  \n",
       "32                                       -       -               -  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame({'RANK':rank3,'STATE':state3,'GSDP(18-19) AT CURRENT PRICES in Cr INR':g18193,'GSDP(19-20) AT CURRENT PRICES in Cr INR':g19203,'SHARE':share3,'GDP ($ BILLION)':gdp3})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad1abc",
   "metadata": {},
   "source": [
    "# PROBLEM NO. 4 - TRENDING REPOSITORIES IN GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "408111e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15f6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4=webdriver.Chrome(r\"chromedriver.exe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c523e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4.get(\"https://github.com/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8871f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search4=driver4.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "search4.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d857a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search44=driver4.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\")\n",
    "search44.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd8f9a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['togethercomputer / OpenChatKit',\n",
       " 'ggerganov / llama.cpp',\n",
       " 'AstroNvim / AstroNvim',\n",
       " 'exaloop / codon',\n",
       " 'Azure-Samples / azure-search-openai-demo',\n",
       " 'davinci1012 / pinduoduo_backdoor_unpacker',\n",
       " 'Postcatlab / postcat',\n",
       " 'Bin-Huang / chatbox',\n",
       " 'midudev / openui.com',\n",
       " 'base-org / node',\n",
       " 'kaixindelele / ChatPaper',\n",
       " 'whoiskatrin / sql-translator',\n",
       " 'microsoft / visual-chatgpt',\n",
       " 'chathub-dev / chathub',\n",
       " 'Genymobile / scrcpy',\n",
       " 'TheAlgorithms / Python',\n",
       " 'ccfos / nightingale',\n",
       " 'tangly1024 / NotionNext',\n",
       " 'svc-develop-team / so-vits-svc',\n",
       " 'EbookFoundation / free-programming-books',\n",
       " 'GanymedeNil / document.ai',\n",
       " 'oobabooga / text-generation-webui',\n",
       " 'ggerganov / whisper.cpp',\n",
       " 'pgrok / pgrok',\n",
       " 'ggerganov / ggml']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo4=[]\n",
    "repo4tag=driver4.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]')\n",
    "for i in repo4tag:\n",
    "    repo4.append(i.text)\n",
    "repo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c9b4977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(repo4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb8e9073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/togethercomputer/OpenChatKit',\n",
       " 'https://github.com/ggerganov/llama.cpp',\n",
       " 'https://github.com/AstroNvim/AstroNvim',\n",
       " 'https://github.com/exaloop/codon',\n",
       " 'https://github.com/Azure-Samples/azure-search-openai-demo',\n",
       " 'https://github.com/davinci1012/pinduoduo_backdoor_unpacker',\n",
       " 'https://github.com/Postcatlab/postcat',\n",
       " 'https://github.com/Bin-Huang/chatbox',\n",
       " 'https://github.com/midudev/openui.com',\n",
       " 'https://github.com/base-org/node',\n",
       " 'https://github.com/kaixindelele/ChatPaper',\n",
       " 'https://github.com/whoiskatrin/sql-translator',\n",
       " 'https://github.com/microsoft/visual-chatgpt',\n",
       " 'https://github.com/chathub-dev/chathub',\n",
       " 'https://github.com/Genymobile/scrcpy',\n",
       " 'https://github.com/TheAlgorithms/Python',\n",
       " 'https://github.com/ccfos/nightingale',\n",
       " 'https://github.com/tangly1024/NotionNext',\n",
       " 'https://github.com/svc-develop-team/so-vits-svc',\n",
       " 'https://github.com/EbookFoundation/free-programming-books',\n",
       " 'https://github.com/GanymedeNil/document.ai',\n",
       " 'https://github.com/oobabooga/text-generation-webui',\n",
       " 'https://github.com/ggerganov/whisper.cpp',\n",
       " 'https://github.com/pgrok/pgrok',\n",
       " 'https://github.com/ggerganov/ggml']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url4=[]\n",
    "url=driver4.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in url:\n",
    "    url4.append(i.get_attribute('href'))\n",
    "url4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5ee5be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(url4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ec4a6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Port of Facebook's LLaMA model in C/C++\",\n",
       " 'AstroNvim is an aesthetic and feature-rich neovim config that is extensible and easy to use with a great set of plugins',\n",
       " 'A high-performance, zero-overhead, extensible Python compiler using LLVM',\n",
       " 'Demonstration of how to leverage Azure OpenAI and Cognitive Search to enable Information Search and Discovery over organizational content',\n",
       " 'Samples and Unpacker of malicious backdoors and exploits developed and used by Pinduoduo',\n",
       " 'Postcat 是一个可扩展的 API 工具平台。集合基础的 API 管理和测试功能，并且可以通过插件简化你的 API 开发工作，让你可以更快更好地创建 API。An extensible API tool.',\n",
       " 'a cross-platform desktop client for OpenAI API, also a prompt debugging and management tool.',\n",
       " 'Generador de componentes de UI con IA',\n",
       " 'Everything required to run your own Base node',\n",
       " 'Use ChatGPT to summarize the arXiv papers.',\n",
       " 'SQL Translator is a tool for converting natural language queries into SQL code using artificial intelligence. This project is 100% free and open source.',\n",
       " 'Official repo for the paper: Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models',\n",
       " 'All-in-one chatbot client',\n",
       " 'Display and control your Android device',\n",
       " 'All Algorithms implemented in Python',\n",
       " 'An enterprise-level cloud-native monitoring system, which can be used as drop-in replacement of Prometheus for alerting and Grafana for visualization.',\n",
       " '一个使用 NextJS + Notion API 实现的，部署在 Vercel 上的静态博客系统。为Notion和所有创作者设计。',\n",
       " 'SoftVC VITS Singing Voice Conversion',\n",
       " '📚 Freely available programming books',\n",
       " '基于向量数据库与GPT3.5的通用本地知识库方案(A universal local knowledge base solution based on vector database and GPT3.5)',\n",
       " 'A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.',\n",
       " \"Port of OpenAI's Whisper model in C/C++\",\n",
       " \"Poor man's ngrok - a multi-tenant HTTP reverse tunnel solution through SSH remote port forwarding\",\n",
       " 'Tensor library for machine learning']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc4=[]\n",
    "try:\n",
    "    des4tag=driver4.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "    for i in des4tag:\n",
    "          desc4.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    desc4.append('-')\n",
    "desc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cba4c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(desc4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5328fa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " \"Port of Facebook's LLaMA model in C/C++\",\n",
       " 'AstroNvim is an aesthetic and feature-rich neovim config that is extensible and easy to use with a great set of plugins',\n",
       " 'A high-performance, zero-overhead, extensible Python compiler using LLVM',\n",
       " 'Demonstration of how to leverage Azure OpenAI and Cognitive Search to enable Information Search and Discovery over organizational content',\n",
       " 'Samples and Unpacker of malicious backdoors and exploits developed and used by Pinduoduo',\n",
       " 'Postcat 是一个可扩展的 API 工具平台。集合基础的 API 管理和测试功能，并且可以通过插件简化你的 API 开发工作，让你可以更快更好地创建 API。An extensible API tool.',\n",
       " 'a cross-platform desktop client for OpenAI API, also a prompt debugging and management tool.',\n",
       " 'Generador de componentes de UI con IA',\n",
       " 'Everything required to run your own Base node',\n",
       " 'Use ChatGPT to summarize the arXiv papers.',\n",
       " 'SQL Translator is a tool for converting natural language queries into SQL code using artificial intelligence. This project is 100% free and open source.',\n",
       " 'Official repo for the paper: Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models',\n",
       " 'All-in-one chatbot client',\n",
       " 'Display and control your Android device',\n",
       " 'All Algorithms implemented in Python',\n",
       " 'An enterprise-level cloud-native monitoring system, which can be used as drop-in replacement of Prometheus for alerting and Grafana for visualization.',\n",
       " '一个使用 NextJS + Notion API 实现的，部署在 Vercel 上的静态博客系统。为Notion和所有创作者设计。',\n",
       " 'SoftVC VITS Singing Voice Conversion',\n",
       " '📚 Freely available programming books',\n",
       " '基于向量数据库与GPT3.5的通用本地知识库方案(A universal local knowledge base solution based on vector database and GPT3.5)',\n",
       " 'A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.',\n",
       " \"Port of OpenAI's Whisper model in C/C++\",\n",
       " \"Poor man's ngrok - a multi-tenant HTTP reverse tunnel solution through SSH remote port forwarding\",\n",
       " 'Tensor library for machine learning']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc4.insert(0,'-')\n",
    "desc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d71e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(desc4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4596ed88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7',\n",
       " '17',\n",
       " '-',\n",
       " '7',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '9',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '9',\n",
       " '-',\n",
       " '-',\n",
       " '',\n",
       " '-',\n",
       " '-',\n",
       " '9',\n",
       " '2,496',\n",
       " '-',\n",
       " '',\n",
       " '65',\n",
       " '6',\n",
       " '3']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con4=[]\n",
    "for i in url4:\n",
    "    driver4.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        contag4=driver4.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[4]/div/h2/a/span')\n",
    "        con4.append(contag4.text)\n",
    "    except NoSuchElementException:\n",
    "        con4.append('-')\n",
    "con4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a55cc662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(con4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28fd7726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'C',\n",
       " 'Lua',\n",
       " 'C++',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'JavaScript',\n",
       " 'TypeScript',\n",
       " 'JavaScript',\n",
       " 'Shell',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'C',\n",
       " 'Python',\n",
       " 'Go',\n",
       " 'JavaScript',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'C',\n",
       " 'Go',\n",
       " 'C']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prolan4=[]\n",
    "try:\n",
    "    prolantag4=driver4.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]/span[2]')\n",
    "    for i in prolantag4:\n",
    "        prolan4.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    prolan4.append('-')\n",
    "prolan4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48f073c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'C',\n",
       " 'Lua',\n",
       " 'C++',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'JavaScript',\n",
       " 'TypeScript',\n",
       " 'JavaScript',\n",
       " 'Shell',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " '-',\n",
       " 'C',\n",
       " 'Python',\n",
       " 'Go',\n",
       " 'JavaScript',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'C',\n",
       " 'Go',\n",
       " 'C']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prolan4.insert(14,'-')\n",
    "prolan4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11f273f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(prolan4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a5c7b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contribution Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>togethercomputer / OpenChatKit</td>\n",
       "      <td>-</td>\n",
       "      <td>7</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ggerganov / llama.cpp</td>\n",
       "      <td>Port of Facebook's LLaMA model in C/C++</td>\n",
       "      <td>17</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AstroNvim / AstroNvim</td>\n",
       "      <td>AstroNvim is an aesthetic and feature-rich neo...</td>\n",
       "      <td>-</td>\n",
       "      <td>Lua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exaloop / codon</td>\n",
       "      <td>A high-performance, zero-overhead, extensible ...</td>\n",
       "      <td>7</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Azure-Samples / azure-search-openai-demo</td>\n",
       "      <td>Demonstration of how to leverage Azure OpenAI ...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>davinci1012 / pinduoduo_backdoor_unpacker</td>\n",
       "      <td>Samples and Unpacker of malicious backdoors an...</td>\n",
       "      <td>-</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Postcatlab / postcat</td>\n",
       "      <td>Postcat 是一个可扩展的 API 工具平台。集合基础的 API 管理和测试功能，并且可...</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bin-Huang / chatbox</td>\n",
       "      <td>a cross-platform desktop client for OpenAI API...</td>\n",
       "      <td>9</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>midudev / openui.com</td>\n",
       "      <td>Generador de componentes de UI con IA</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base-org / node</td>\n",
       "      <td>Everything required to run your own Base node</td>\n",
       "      <td>-</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kaixindelele / ChatPaper</td>\n",
       "      <td>Use ChatGPT to summarize the arXiv papers.</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>whoiskatrin / sql-translator</td>\n",
       "      <td>SQL Translator is a tool for converting natura...</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>microsoft / visual-chatgpt</td>\n",
       "      <td>Official repo for the paper: Visual ChatGPT: T...</td>\n",
       "      <td>9</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chathub-dev / chathub</td>\n",
       "      <td>All-in-one chatbot client</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Genymobile / scrcpy</td>\n",
       "      <td>Display and control your Android device</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ccfos / nightingale</td>\n",
       "      <td>An enterprise-level cloud-native monitoring sy...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tangly1024 / NotionNext</td>\n",
       "      <td>一个使用 NextJS + Notion API 实现的，部署在 Vercel 上的静态博客...</td>\n",
       "      <td>-</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>svc-develop-team / so-vits-svc</td>\n",
       "      <td>SoftVC VITS Singing Voice Conversion</td>\n",
       "      <td>9</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>2,496</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GanymedeNil / document.ai</td>\n",
       "      <td>基于向量数据库与GPT3.5的通用本地知识库方案(A universal local kno...</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>oobabooga / text-generation-webui</td>\n",
       "      <td>A gradio web UI for running Large Language Mod...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ggerganov / whisper.cpp</td>\n",
       "      <td>Port of OpenAI's Whisper model in C/C++</td>\n",
       "      <td>65</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pgrok / pgrok</td>\n",
       "      <td>Poor man's ngrok - a multi-tenant HTTP reverse...</td>\n",
       "      <td>6</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ggerganov / ggml</td>\n",
       "      <td>Tensor library for machine learning</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Repository Title  \\\n",
       "0              togethercomputer / OpenChatKit   \n",
       "1                       ggerganov / llama.cpp   \n",
       "2                       AstroNvim / AstroNvim   \n",
       "3                             exaloop / codon   \n",
       "4    Azure-Samples / azure-search-openai-demo   \n",
       "5   davinci1012 / pinduoduo_backdoor_unpacker   \n",
       "6                        Postcatlab / postcat   \n",
       "7                         Bin-Huang / chatbox   \n",
       "8                        midudev / openui.com   \n",
       "9                             base-org / node   \n",
       "10                   kaixindelele / ChatPaper   \n",
       "11               whoiskatrin / sql-translator   \n",
       "12                 microsoft / visual-chatgpt   \n",
       "13                      chathub-dev / chathub   \n",
       "14                        Genymobile / scrcpy   \n",
       "15                     TheAlgorithms / Python   \n",
       "16                        ccfos / nightingale   \n",
       "17                    tangly1024 / NotionNext   \n",
       "18             svc-develop-team / so-vits-svc   \n",
       "19   EbookFoundation / free-programming-books   \n",
       "20                  GanymedeNil / document.ai   \n",
       "21          oobabooga / text-generation-webui   \n",
       "22                    ggerganov / whisper.cpp   \n",
       "23                              pgrok / pgrok   \n",
       "24                           ggerganov / ggml   \n",
       "\n",
       "                               Repository Description Contribution Count  \\\n",
       "0                                                   -                  7   \n",
       "1             Port of Facebook's LLaMA model in C/C++                 17   \n",
       "2   AstroNvim is an aesthetic and feature-rich neo...                  -   \n",
       "3   A high-performance, zero-overhead, extensible ...                  7   \n",
       "4   Demonstration of how to leverage Azure OpenAI ...                  -   \n",
       "5   Samples and Unpacker of malicious backdoors an...                  -   \n",
       "6   Postcat 是一个可扩展的 API 工具平台。集合基础的 API 管理和测试功能，并且可...                  -   \n",
       "7   a cross-platform desktop client for OpenAI API...                  9   \n",
       "8               Generador de componentes de UI con IA                  -   \n",
       "9       Everything required to run your own Base node                  -   \n",
       "10         Use ChatGPT to summarize the arXiv papers.                  -   \n",
       "11  SQL Translator is a tool for converting natura...                  -   \n",
       "12  Official repo for the paper: Visual ChatGPT: T...                  9   \n",
       "13                          All-in-one chatbot client                  -   \n",
       "14            Display and control your Android device                  -   \n",
       "15               All Algorithms implemented in Python                      \n",
       "16  An enterprise-level cloud-native monitoring sy...                  -   \n",
       "17  一个使用 NextJS + Notion API 实现的，部署在 Vercel 上的静态博客...                  -   \n",
       "18               SoftVC VITS Singing Voice Conversion                  9   \n",
       "19               📚 Freely available programming books              2,496   \n",
       "20  基于向量数据库与GPT3.5的通用本地知识库方案(A universal local kno...                  -   \n",
       "21  A gradio web UI for running Large Language Mod...                      \n",
       "22            Port of OpenAI's Whisper model in C/C++                 65   \n",
       "23  Poor man's ngrok - a multi-tenant HTTP reverse...                  6   \n",
       "24                Tensor library for machine learning                  3   \n",
       "\n",
       "   Language Used  \n",
       "0         Python  \n",
       "1              C  \n",
       "2            Lua  \n",
       "3            C++  \n",
       "4         Python  \n",
       "5           Java  \n",
       "6     JavaScript  \n",
       "7     TypeScript  \n",
       "8     JavaScript  \n",
       "9          Shell  \n",
       "10        Python  \n",
       "11    TypeScript  \n",
       "12        Python  \n",
       "13    TypeScript  \n",
       "14             -  \n",
       "15             C  \n",
       "16        Python  \n",
       "17            Go  \n",
       "18    JavaScript  \n",
       "19        Python  \n",
       "20        Python  \n",
       "21        Python  \n",
       "22             C  \n",
       "23            Go  \n",
       "24             C  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.DataFrame({'Repository Title':repo4,'Repository Description':desc4,'Contribution Count':con4,'Language Used':prolan4})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0c753",
   "metadata": {},
   "source": [
    "# PROBLEM NO.5 - TOP 100 SONGS ON BILLBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3acb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f47bed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5=webdriver.Chrome(r\"chromedriver.exe\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12f2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5.get(\"https://www.billboard.com/\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447f9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search50=driver5.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\")\n",
    "search50.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search51=driver5.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a\")\n",
    "search51.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f185ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "search52=driver5.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a\")\n",
    "search52.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f1deaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last Night',\n",
       " 'Flowers',\n",
       " 'Kill Bill',\n",
       " 'Die For You',\n",
       " \"Boy's A Liar, Pt. 2\",\n",
       " \"Creepin'\",\n",
       " 'Thought You Should Know',\n",
       " 'You Proof',\n",
       " \"Thinkin' Bout Me\",\n",
       " 'One Thing At A Time',\n",
       " \"Ain't That Some\",\n",
       " 'Anti-Hero',\n",
       " 'Red Ruby Da Sleeze',\n",
       " 'Everything I Love',\n",
       " 'Man Made A Bar',\n",
       " 'Unholy',\n",
       " 'TQG',\n",
       " 'I Wrote The Book',\n",
       " 'Calm Down',\n",
       " 'Rock And A Hard Place',\n",
       " \"I'm Good (Blue)\",\n",
       " 'Just Wanna Rock',\n",
       " 'As It Was',\n",
       " 'Players',\n",
       " 'Cuff It',\n",
       " 'Under The Influence',\n",
       " \"'98 Braves\",\n",
       " 'Thank God',\n",
       " \"Devil Don't Know\",\n",
       " 'Sunrise',\n",
       " 'Lavender Haze',\n",
       " 'Born With A Beer In My Hand',\n",
       " 'Escapism',\n",
       " 'Rich Flex',\n",
       " 'Whiskey Friends',\n",
       " 'Going, Going, Gone',\n",
       " 'Sure Thing',\n",
       " 'Tennessee Numbers',\n",
       " 'Until I Found You',\n",
       " 'Cowgirls',\n",
       " \"Hope That's True\",\n",
       " 'Something In The Orange',\n",
       " 'Dying Man',\n",
       " 'Keith Whitley',\n",
       " 'Superhero (Heroes & Villains)',\n",
       " 'Snooze',\n",
       " 'In The Bible',\n",
       " 'Neon Star (Country Boy Lullaby)',\n",
       " 'Golden Hour',\n",
       " 'Shirt',\n",
       " 'Me + All Your Reasons',\n",
       " 'I Deserve A Drink',\n",
       " 'F150-50',\n",
       " 'Tennessee Fan',\n",
       " 'Heart Like A Truck',\n",
       " 'Single Than She Was',\n",
       " 'Made You Look',\n",
       " 'Wait In The Truck',\n",
       " 'Wine Into Water',\n",
       " 'On The Street',\n",
       " 'Days That End In Why',\n",
       " 'Painting Pictures',\n",
       " '180 (Lifestyle)',\n",
       " 'Bebe Dame',\n",
       " 'Last Drive Down Main',\n",
       " 'Bloody Mary',\n",
       " 'Favorite Song',\n",
       " 'Spin Bout U',\n",
       " \"Good Girl Gone Missin'\",\n",
       " 'Bzrp Music Sessions, Vol. 53',\n",
       " 'Me To Me',\n",
       " 'Money On Me',\n",
       " 'Nobody Gets Me',\n",
       " 'Love You Anyway',\n",
       " 'Had It',\n",
       " 'Outlook',\n",
       " \"Don't Think Jesus\",\n",
       " 'Special',\n",
       " \"What He Didn't Do\",\n",
       " 'Ceilings',\n",
       " 'Wild As Her',\n",
       " 'Watch This (ARIZONATEARS Pluggnb Remix)',\n",
       " 'Handle On You',\n",
       " 'Next Thing You Know',\n",
       " 'In Ha Mood',\n",
       " 'Freestyle',\n",
       " 'Dawns',\n",
       " 'Love Again',\n",
       " 'Private Landing',\n",
       " 'Que Vuelvas',\n",
       " 'Tennessee Orange',\n",
       " 'Low',\n",
       " 'X Si Volvemos',\n",
       " 'Trance',\n",
       " 'Forever',\n",
       " 'Nonsense',\n",
       " 'AMG',\n",
       " 'Lift Me Up',\n",
       " \"You Didn't\",\n",
       " '10:35']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn5=[]\n",
    "sn5tag=driver5.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li/h3')\n",
    "for i in sn5tag:\n",
    "    sn5.append(i.text)\n",
    "sn5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71d77715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(sn5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b102d97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " '2',\n",
       " '3',\n",
       " '1',\n",
       " '4',\n",
       " '6',\n",
       " '13',\n",
       " '21',\n",
       " '-',\n",
       " '51',\n",
       " '-',\n",
       " '9',\n",
       " '-',\n",
       " '93',\n",
       " '-',\n",
       " '8',\n",
       " '7',\n",
       " '64',\n",
       " '15',\n",
       " '17',\n",
       " '11',\n",
       " '12',\n",
       " '14',\n",
       " '16',\n",
       " '10',\n",
       " '18',\n",
       " '-',\n",
       " '19',\n",
       " '-',\n",
       " '-',\n",
       " '23',\n",
       " '-',\n",
       " '22',\n",
       " '20',\n",
       " '-',\n",
       " '24',\n",
       " '28',\n",
       " '-',\n",
       " '27',\n",
       " '-',\n",
       " '-',\n",
       " '26',\n",
       " '-',\n",
       " '-',\n",
       " '30',\n",
       " '32',\n",
       " '-',\n",
       " '-',\n",
       " '31',\n",
       " '33',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '29',\n",
       " '-',\n",
       " '34',\n",
       " '40',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '25',\n",
       " '-',\n",
       " '41',\n",
       " '-',\n",
       " '46',\n",
       " '44',\n",
       " '47',\n",
       " '-',\n",
       " '42',\n",
       " '-',\n",
       " '-',\n",
       " '43',\n",
       " '39',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '53',\n",
       " '54',\n",
       " '60',\n",
       " '58',\n",
       " '56',\n",
       " '55',\n",
       " '67',\n",
       " '69',\n",
       " '61',\n",
       " '52',\n",
       " '59',\n",
       " '72',\n",
       " '57',\n",
       " '70',\n",
       " '63',\n",
       " '48',\n",
       " '87',\n",
       " '76',\n",
       " '75',\n",
       " '80',\n",
       " '65',\n",
       " '78',\n",
       " '81']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lwr5=[]\n",
    "lwr5tag=driver5.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]')\n",
    "for i in lwr5tag:\n",
    "    lwr5.append(i.text)\n",
    "lwr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ceb0341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(lwr5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a074d194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '3',\n",
       " '7',\n",
       " '5',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '1',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '1',\n",
       " '7',\n",
       " '18',\n",
       " '15',\n",
       " '16',\n",
       " '4',\n",
       " '10',\n",
       " '1',\n",
       " '16',\n",
       " '6',\n",
       " '12',\n",
       " '27',\n",
       " '13',\n",
       " '29',\n",
       " '30',\n",
       " '2',\n",
       " '32',\n",
       " '22',\n",
       " '2',\n",
       " '35',\n",
       " '23',\n",
       " '28',\n",
       " '38',\n",
       " '23',\n",
       " '40',\n",
       " '41',\n",
       " '10',\n",
       " '43',\n",
       " '44',\n",
       " '8',\n",
       " '29',\n",
       " '47',\n",
       " '48',\n",
       " '10',\n",
       " '11',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '49',\n",
       " '29',\n",
       " '56',\n",
       " '11',\n",
       " '23',\n",
       " '59',\n",
       " '60',\n",
       " '57',\n",
       " '25',\n",
       " '63',\n",
       " '25',\n",
       " '65',\n",
       " '46',\n",
       " '44',\n",
       " '5',\n",
       " '69',\n",
       " '9',\n",
       " '71',\n",
       " '72',\n",
       " '10',\n",
       " '15',\n",
       " '75',\n",
       " '76',\n",
       " '7',\n",
       " '52',\n",
       " '53',\n",
       " '60',\n",
       " '58',\n",
       " '56',\n",
       " '55',\n",
       " '67',\n",
       " '68',\n",
       " '59',\n",
       " '42',\n",
       " '40',\n",
       " '72',\n",
       " '50',\n",
       " '53',\n",
       " '17',\n",
       " '48',\n",
       " '42',\n",
       " '8',\n",
       " '56',\n",
       " '66',\n",
       " '2',\n",
       " '63',\n",
       " '69']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr5=[]\n",
    "pr5tag=driver5.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]')\n",
    "for i in pr5tag:\n",
    "    pr5.append(i.text)\n",
    "pr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7f1ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(pr5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6bf95a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6',\n",
       " '8',\n",
       " '13',\n",
       " '32',\n",
       " '5',\n",
       " '14',\n",
       " '30',\n",
       " '43',\n",
       " '1',\n",
       " '14',\n",
       " '1',\n",
       " '20',\n",
       " '1',\n",
       " '6',\n",
       " '1',\n",
       " '24',\n",
       " '2',\n",
       " '6',\n",
       " '27',\n",
       " '39',\n",
       " '28',\n",
       " '21',\n",
       " '49',\n",
       " '10',\n",
       " '30',\n",
       " '26',\n",
       " '1',\n",
       " '26',\n",
       " '1',\n",
       " '1',\n",
       " '20',\n",
       " '1',\n",
       " '14',\n",
       " '18',\n",
       " '1',\n",
       " '17',\n",
       " '32',\n",
       " '1',\n",
       " '36',\n",
       " '1',\n",
       " '1',\n",
       " '46',\n",
       " '1',\n",
       " '1',\n",
       " '14',\n",
       " '13',\n",
       " '1',\n",
       " '1',\n",
       " '28',\n",
       " '19',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '6',\n",
       " '17',\n",
       " '1',\n",
       " '20',\n",
       " '27',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '4',\n",
       " '1',\n",
       " '11',\n",
       " '1',\n",
       " '10',\n",
       " '3',\n",
       " '18',\n",
       " '1',\n",
       " '8',\n",
       " '1',\n",
       " '1',\n",
       " '13',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '6',\n",
       " '4',\n",
       " '12',\n",
       " '3',\n",
       " '22',\n",
       " '3',\n",
       " '10',\n",
       " '7',\n",
       " '5',\n",
       " '23',\n",
       " '6',\n",
       " '6',\n",
       " '2',\n",
       " '11',\n",
       " '13',\n",
       " '13',\n",
       " '5',\n",
       " '5',\n",
       " '9',\n",
       " '8',\n",
       " '7',\n",
       " '19',\n",
       " '9',\n",
       " '7']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w5=[]\n",
    "w5tag=driver5.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]')\n",
    "for i in w5tag:\n",
    "    w5.append(i.text)\n",
    "w5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddc92847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(w5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ef72eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Morgan Wallen',\n",
       " 'Miley Cyrus',\n",
       " 'SZA',\n",
       " 'The Weeknd & Ariana Grande',\n",
       " 'PinkPantheress & Ice Spice',\n",
       " 'Metro Boomin, The Weeknd & 21 Savage',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Taylor Swift',\n",
       " 'Nicki Minaj',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen Featuring Eric Church',\n",
       " 'Sam Smith & Kim Petras',\n",
       " 'Karol G x Shakira',\n",
       " 'Morgan Wallen',\n",
       " 'Rema & Selena Gomez',\n",
       " 'Bailey Zimmerman',\n",
       " 'David Guetta & Bebe Rexha',\n",
       " 'Lil Uzi Vert',\n",
       " 'Harry Styles',\n",
       " 'Coi Leray',\n",
       " 'Beyonce',\n",
       " 'Chris Brown',\n",
       " 'Morgan Wallen',\n",
       " 'Kane Brown With Katelyn Brown',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Taylor Swift',\n",
       " 'Morgan Wallen',\n",
       " 'RAYE Featuring 070 Shake',\n",
       " 'Drake & 21 Savage',\n",
       " 'Morgan Wallen',\n",
       " 'Luke Combs',\n",
       " 'Miguel',\n",
       " 'Morgan Wallen',\n",
       " 'Stephen Sanchez',\n",
       " 'Morgan Wallen Featuring ERNEST',\n",
       " 'Morgan Wallen',\n",
       " 'Zach Bryan',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Metro Boomin, Future & Chris Brown',\n",
       " 'SZA',\n",
       " 'Morgan Wallen Featuring HARDY',\n",
       " 'Morgan Wallen',\n",
       " 'JVKE',\n",
       " 'SZA',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Lainey Wilson',\n",
       " 'Morgan Wallen',\n",
       " 'Meghan Trainor',\n",
       " 'HARDY Featuring Lainey Wilson',\n",
       " 'Morgan Wallen',\n",
       " 'j-hope With J. Cole',\n",
       " 'Morgan Wallen',\n",
       " 'Superstar Pride',\n",
       " 'Morgan Wallen',\n",
       " 'Fuerza Regida X Grupo Frontera',\n",
       " 'Morgan Wallen',\n",
       " 'Lady Gaga',\n",
       " 'Toosii',\n",
       " 'Drake & 21 Savage',\n",
       " 'Morgan Wallen',\n",
       " 'Bizarrap & Shakira',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'SZA',\n",
       " 'Luke Combs',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Morgan Wallen',\n",
       " 'Lizzo Featuring SZA',\n",
       " 'Carly Pearce',\n",
       " 'Lizzy McAlpine',\n",
       " 'Corey Kent',\n",
       " 'Lil Uzi Vert',\n",
       " 'Parker McCollum',\n",
       " 'Jordan Davis',\n",
       " 'Ice Spice',\n",
       " 'Lil Baby',\n",
       " 'Zach Bryan Featuring Maggie Rogers',\n",
       " 'The Kid LAROI',\n",
       " 'Don Toliver Featuring Justin Bieber & Future',\n",
       " 'Carin Leon X Grupo Frontera',\n",
       " 'Megan Moroney',\n",
       " 'SZA',\n",
       " 'Karol G x Romeo Santos',\n",
       " 'Metro Boomin, Travis Scott & Young Thug',\n",
       " 'Lil Baby Featuring Fridayy',\n",
       " 'Sabrina Carpenter',\n",
       " 'Gabito Ballesteros, Peso Pluma & Natanael Cano',\n",
       " 'Rihanna',\n",
       " 'Brett Young',\n",
       " 'Tiesto Featuring Tate McRae']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a5=[]\n",
    "a5tag=driver5.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/span')\n",
    "for i in a5tag:\n",
    "    a5.append(i.text)\n",
    "a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51567f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(a5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4a5719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die For You</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy's A Liar, Pt. 2</td>\n",
       "      <td>PinkPantheress &amp; Ice Spice</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nonsense</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AMG</td>\n",
       "      <td>Gabito Ballesteros, Peso Pluma &amp; Natanael Cano</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Lift Me Up</td>\n",
       "      <td>Rihanna</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>You Didn't</td>\n",
       "      <td>Brett Young</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10:35</td>\n",
       "      <td>Tiesto Featuring Tate McRae</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Song Name                                     Artist Name  \\\n",
       "0            Last Night                                   Morgan Wallen   \n",
       "1               Flowers                                     Miley Cyrus   \n",
       "2             Kill Bill                                             SZA   \n",
       "3           Die For You                      The Weeknd & Ariana Grande   \n",
       "4   Boy's A Liar, Pt. 2                      PinkPantheress & Ice Spice   \n",
       "..                  ...                                             ...   \n",
       "95             Nonsense                               Sabrina Carpenter   \n",
       "96                  AMG  Gabito Ballesteros, Peso Pluma & Natanael Cano   \n",
       "97           Lift Me Up                                         Rihanna   \n",
       "98           You Didn't                                     Brett Young   \n",
       "99                10:35                     Tiesto Featuring Tate McRae   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks on Board  \n",
       "0               5         1              6  \n",
       "1               2         1              8  \n",
       "2               3         2             13  \n",
       "3               1         1             32  \n",
       "4               4         3              5  \n",
       "..            ...       ...            ...  \n",
       "95             75        56              8  \n",
       "96             80        66              7  \n",
       "97             65         2             19  \n",
       "98             78        63              9  \n",
       "99             81        69              7  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame({'Song Name':sn5,'Artist Name':a5,'Last Week Rank':lwr5,'Peak Rank':pr5,'Weeks on Board':w5})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45064f37",
   "metadata": {},
   "source": [
    "# PROBLEM NO.6 - HIGHEST SELLING NOVELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e547e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87535055",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18d44f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6660dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bname6=[]\n",
    "bname6tag=driver6.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in bname6tag:\n",
    "    bname6.append(i.text)\n",
    "bname6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05cce881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(bname6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32b0cdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aname6=[]\n",
    "aname6tag=driver6.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for i in aname6tag:\n",
    "    aname6.append(i.text)\n",
    "aname6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6789852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(aname6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "835db58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vname6=[]\n",
    "vname6tag=driver6.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for i in vname6tag:\n",
    "    vname6.append(i.text)\n",
    "vname6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b080157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(vname6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96086f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pname6=[]\n",
    "pname6tag=driver6.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for i in pname6tag:\n",
    "    pname6.append(i.text)\n",
    "pname6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4182edc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(pname6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b794fea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gname6=[]\n",
    "gname6tag=driver6.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for i in gname6tag:\n",
    "    gname6.append(i.text)\n",
    "gname6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26e5545f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(gname6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a65adb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.DataFrame({'Book Name':bname6,'Author Name':aname6,'Volumes Sold':vname6,'Publisher':pname6,'Genre':gname6})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ea439",
   "metadata": {},
   "source": [
    "# PROBLEM NO.7 - MOST WATCHED TV SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46048ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47a31ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03374b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7.get(\"http://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d23b3e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name7=[]\n",
    "name7tag=driver7.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "for i in name7tag:\n",
    "    name7.append(i.text)\n",
    "name7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73fda67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(name7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c47f3167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016–2024)',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011–2019)',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016–2022)',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2013)',\n",
       " '(2015–2023)',\n",
       " '(1999– )',\n",
       " '(2013–2023)',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016–2023)',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005– )',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y7=[]\n",
    "y7tag=driver7.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "for i in y7tag:\n",
    "    y7.append(i.text)\n",
    "y7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ebab487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(y7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91a8151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g7=[]\n",
    "g7tag=driver7.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[1]/span[5]')\n",
    "for i in g7tag:\n",
    "    g7.append(i.text)\n",
    "g7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a108e3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(g7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a83ec4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt7=[]\n",
    "rt7tag=driver7.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[1]/span[5]')\n",
    "for i in rt7tag:\n",
    "    rt7.append(i.text)\n",
    "rt7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15342c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(rt7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46e0a3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '6.8',\n",
       " '8.2',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.4',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '6.8',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.5',\n",
       " '7.9',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.6',\n",
       " '8.9',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.2',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.2',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.6',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.4',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r7=[]\n",
    "r7tag=driver7.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/div/div/span[2]')\n",
    "for i in r7tag:\n",
    "    r7.append(i.text)\n",
    "r7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "357634ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(r7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "749c15d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,137,644',\n",
       " '1,222,630',\n",
       " '1,014,783',\n",
       " '298,925',\n",
       " '257,797',\n",
       " '307,132',\n",
       " '147,188',\n",
       " '316,748',\n",
       " '351,955',\n",
       " '435,403',\n",
       " '488,927',\n",
       " '821,466',\n",
       " '561,743',\n",
       " '941,074',\n",
       " '544,945',\n",
       " '170,566',\n",
       " '327,976',\n",
       " '324,602',\n",
       " '1,940,767',\n",
       " '331,780',\n",
       " '453,763',\n",
       " '545,797',\n",
       " '155,586',\n",
       " '153,953',\n",
       " '413,794',\n",
       " '227,883',\n",
       " '433,362',\n",
       " '448,432',\n",
       " '1,014,324',\n",
       " '694,470',\n",
       " '419,347',\n",
       " '394,470',\n",
       " '139,208',\n",
       " '125,722',\n",
       " '178,954',\n",
       " '156,775',\n",
       " '233,249',\n",
       " '512,152',\n",
       " '217,738',\n",
       " '441,762',\n",
       " '541,809',\n",
       " '65,656',\n",
       " '198,531',\n",
       " '510,658',\n",
       " '402,166',\n",
       " '82,660',\n",
       " '293,017',\n",
       " '249,427',\n",
       " '230,324',\n",
       " '219,430',\n",
       " '265,284',\n",
       " '733,714',\n",
       " '133,064',\n",
       " '347,009',\n",
       " '255,826',\n",
       " '562,118',\n",
       " '569,302',\n",
       " '473,373',\n",
       " '61,756',\n",
       " '112,604',\n",
       " '346,669',\n",
       " '75,527',\n",
       " '106,526',\n",
       " '244,315',\n",
       " '98,892',\n",
       " '98,835',\n",
       " '52,967',\n",
       " '150,601',\n",
       " '379,327',\n",
       " '326,437',\n",
       " '108,086',\n",
       " '254,694',\n",
       " '584,767',\n",
       " '107,218',\n",
       " '131,636',\n",
       " '556,216',\n",
       " '110,429',\n",
       " '243,348',\n",
       " '93,268',\n",
       " '23,425',\n",
       " '147,754',\n",
       " '167,432',\n",
       " '133,711',\n",
       " '38,587',\n",
       " '299,296',\n",
       " '121,505',\n",
       " '133,750',\n",
       " '75,536',\n",
       " '110,422',\n",
       " '205,971',\n",
       " '29,976',\n",
       " '188,848',\n",
       " '227,116',\n",
       " '781,379',\n",
       " '70,061',\n",
       " '51,002',\n",
       " '63,015',\n",
       " '204,854',\n",
       " '42,420',\n",
       " '253,474']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v7=[]\n",
    "v7tag=driver7.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "for i in v7tag:\n",
    "    v7.append(i.text)\n",
    "v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90fc3fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(v7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59306e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,137,644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,222,630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,014,783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.5</td>\n",
       "      <td>298,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>257,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.1</td>\n",
       "      <td>204,854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>8.6</td>\n",
       "      <td>253,474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "                    Run Time Ratings      Votes  \n",
       "0   Action, Adventure, Drama     9.2  2,137,644  \n",
       "1     Drama, Fantasy, Horror     8.7  1,222,630  \n",
       "2    Drama, Horror, Thriller     8.1  1,014,783  \n",
       "3   Drama, Mystery, Thriller     7.5    298,925  \n",
       "4     Drama, Mystery, Sci-Fi     7.6    257,797  \n",
       "..                       ...     ...        ...  \n",
       "95                     Drama     7.4     51,002  \n",
       "96  Adventure, Comedy, Drama     7.8     63,015  \n",
       "97     Crime, Drama, Mystery     8.1    204,854  \n",
       "98      Comedy, Crime, Drama     7.1     42,420  \n",
       "99    Drama, Horror, Mystery     8.6    253,474  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7=pd.DataFrame({'Name':name7,'Year Span':y7,'Genre':g7,'Run Time':rt7,'Ratings':r7,'Votes':v7})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e548e5",
   "metadata": {},
   "source": [
    "# PROBLEM NO.8 - UCI MACHINE LEARNING REPOSITORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b758cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38aae88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488d9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefde2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search8=driver8.find_element(By.XPATH,\"/html/body/table[2]/tbody/tr/td/span/b/a\")\n",
    "search8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87bb5ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " '  Abalone',\n",
       " '  Adult',\n",
       " '  Annealing',\n",
       " '  Anonymous Microsoft Web Data',\n",
       " '  Arrhythmia',\n",
       " '  Artificial Characters',\n",
       " '  Audiology (Original)',\n",
       " '  Audiology (Standardized)',\n",
       " '  Auto MPG',\n",
       " '  Automobile',\n",
       " '  Badges',\n",
       " '  Balance Scale',\n",
       " '  Balloons',\n",
       " '  Breast Cancer',\n",
       " '  Breast Cancer Wisconsin (Original)',\n",
       " '  Breast Cancer Wisconsin (Prognostic)',\n",
       " '  Breast Cancer Wisconsin (Diagnostic)',\n",
       " '  Pittsburgh Bridges',\n",
       " '  Car Evaluation',\n",
       " '  Census Income',\n",
       " '  Chess (King-Rook vs. King-Knight)',\n",
       " '  Chess (King-Rook vs. King-Pawn)',\n",
       " '  Chess (King-Rook vs. King)',\n",
       " '  Chess (Domain Theories)',\n",
       " '  Bach Chorales',\n",
       " '  Connect-4',\n",
       " '  Credit Approval',\n",
       " '  Japanese Credit Screening',\n",
       " '  Computer Hardware',\n",
       " '  Contraceptive Method Choice',\n",
       " '  Covertype',\n",
       " '  Cylinder Bands',\n",
       " '  Dermatology',\n",
       " '  Diabetes',\n",
       " '  DGP2 - The Second Data Generation Program',\n",
       " '  Document Understanding',\n",
       " '  EBL Domain Theories',\n",
       " '  Echocardiogram',\n",
       " '  Ecoli',\n",
       " '  Flags',\n",
       " '  Function Finding',\n",
       " '  Glass Identification',\n",
       " \"  Haberman's Survival\",\n",
       " '  Hayes-Roth',\n",
       " '  Heart Disease',\n",
       " '  Hepatitis',\n",
       " '  Horse Colic',\n",
       " '  ICU',\n",
       " '  Image Segmentation',\n",
       " '  Internet Advertisements',\n",
       " '  Ionosphere',\n",
       " '  Iris',\n",
       " '  ISOLET',\n",
       " '  Kinship',\n",
       " '  Labor Relations',\n",
       " '  LED Display Domain',\n",
       " '  Lenses',\n",
       " '  Letter Recognition',\n",
       " '  Liver Disorders',\n",
       " '  Logic Theorist',\n",
       " '  Lung Cancer',\n",
       " '  Lymphography',\n",
       " '  Mechanical Analysis',\n",
       " '  Meta-data',\n",
       " '  Mobile Robots',\n",
       " '  Molecular Biology (Promoter Gene Sequences)',\n",
       " '  Molecular Biology (Protein Secondary Structure)',\n",
       " '  Molecular Biology (Splice-junction Gene Sequences)',\n",
       " \"  MONK's Problems\",\n",
       " '  Moral Reasoner',\n",
       " '  Multiple Features',\n",
       " '  Mushroom',\n",
       " '  Musk (Version 1)',\n",
       " '  Musk (Version 2)',\n",
       " '  Nursery',\n",
       " '  Othello Domain Theory',\n",
       " '  Page Blocks Classification',\n",
       " '  Optical Recognition of Handwritten Digits',\n",
       " '  Pen-Based Recognition of Handwritten Digits',\n",
       " '  Post-Operative Patient',\n",
       " '  Primary Tumor',\n",
       " '  Prodigy',\n",
       " '  Qualitative Structure Activity Relationships',\n",
       " '  Quadruped Mammals',\n",
       " '  Servo',\n",
       " '  Shuttle Landing Control',\n",
       " '  Solar Flare',\n",
       " '  Soybean (Large)',\n",
       " '  Soybean (Small)',\n",
       " '  Challenger USA Space Shuttle O-Ring',\n",
       " '  Low Resolution Spectrometer',\n",
       " '  Spambase',\n",
       " '  SPECT Heart',\n",
       " '  SPECTF Heart',\n",
       " '  Sponge',\n",
       " '  Statlog Project',\n",
       " '  Student Loan Relational',\n",
       " '  Teaching Assistant Evaluation',\n",
       " '  Tic-Tac-Toe Endgame',\n",
       " '  Thyroid Disease',\n",
       " '  Trains',\n",
       " '  University',\n",
       " '  Congressional Voting Records',\n",
       " '  Water Treatment Plant',\n",
       " '  Waveform Database Generator (Version 1)',\n",
       " '  Waveform Database Generator (Version 2)',\n",
       " '  Wine',\n",
       " '  Yeast',\n",
       " '  Zoo',\n",
       " '  Undocumented',\n",
       " '  Twenty Newsgroups',\n",
       " '  Australian Sign Language signs',\n",
       " '  Australian Sign Language signs (High Quality)',\n",
       " '  US Census Data (1990)',\n",
       " '  Census-Income (KDD)',\n",
       " '  Coil 1999 Competition Data',\n",
       " '  Corel Image Features',\n",
       " '  E. Coli Genes',\n",
       " '  EEG Database',\n",
       " '  El Nino',\n",
       " '  Entree Chicago Recommendation Data',\n",
       " '  CMU Face Images',\n",
       " '  Insurance Company Benchmark (COIL 2000)',\n",
       " '  Internet Usage Data',\n",
       " '  IPUMS Census Database',\n",
       " '  Japanese Vowels',\n",
       " '  KDD Cup 1998 Data',\n",
       " '  KDD Cup 1999 Data',\n",
       " '  M. Tuberculosis Genes',\n",
       " '  Movie',\n",
       " '  MSNBC.com Anonymous Web Data',\n",
       " '  NSF Research Award Abstracts 1990-2003',\n",
       " '  Pioneer-1 Mobile Robot Data',\n",
       " '  Pseudo Periodic Synthetic Time Series',\n",
       " '  Reuters-21578 Text Categorization Collection',\n",
       " '  Robot Execution Failures',\n",
       " '  Synthetic Control Chart Time Series',\n",
       " '  Syskill and Webert Web Page Ratings',\n",
       " '  UNIX User Data',\n",
       " '  Volcanoes on Venus - JARtool experiment',\n",
       " '  Statlog (Australian Credit Approval)',\n",
       " '  Statlog (German Credit Data)',\n",
       " '  Statlog (Heart)',\n",
       " '  Statlog (Landsat Satellite)',\n",
       " '  Statlog (Image Segmentation)',\n",
       " '  Statlog (Shuttle)',\n",
       " '  Statlog (Vehicle Silhouettes)',\n",
       " '  Connectionist Bench (Nettalk Corpus)',\n",
       " '  Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       " '  Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       " '  Economic Sanctions',\n",
       " '  Protein Data',\n",
       " '  Cloud',\n",
       " '  CalIt2 Building People Counts',\n",
       " '  Dodgers Loop Sensor',\n",
       " '  Poker Hand',\n",
       " '  MAGIC Gamma Telescope',\n",
       " '  UJI Pen Characters',\n",
       " '  Mammographic Mass',\n",
       " '  Forest Fires',\n",
       " '  Reuters Transcribed Subset',\n",
       " '  Bag of Words',\n",
       " '  Concrete Compressive Strength',\n",
       " '  Hill-Valley',\n",
       " '  Arcene',\n",
       " '  Dexter',\n",
       " '  Dorothea',\n",
       " '  Gisette',\n",
       " '  Madelon',\n",
       " '  Ozone Level Detection',\n",
       " '  Abscisic Acid Signaling Network',\n",
       " '  Parkinsons',\n",
       " '  Character Trajectories',\n",
       " '  Blood Transfusion Service Center',\n",
       " '  UJI Pen Characters (Version 2)',\n",
       " '  Semeion Handwritten Digit',\n",
       " '  SECOM',\n",
       " '  Plants',\n",
       " '  Libras Movement',\n",
       " '  Concrete Slump Test',\n",
       " '  Communities and Crime',\n",
       " '  Acute Inflammations',\n",
       " '  Wine Quality',\n",
       " '  URL Reputation',\n",
       " '  p53 Mutants',\n",
       " '  Parkinsons Telemonitoring',\n",
       " '  Demospongiae',\n",
       " '  Opinosis Opinion ⁄ Review',\n",
       " '  Breast Tissue',\n",
       " '  Cardiotocography',\n",
       " '  Wall-Following Robot Navigation Data',\n",
       " '  Spoken Arabic Digit',\n",
       " '  Localization Data for Person Activity',\n",
       " '  AutoUniv',\n",
       " '  Steel Plates Faults',\n",
       " '  MiniBooNE particle identification',\n",
       " '  YearPredictionMSD',\n",
       " '  PEMS-SF',\n",
       " '  OpinRank Review Dataset',\n",
       " '  Relative location of CT slices on axial axis',\n",
       " '  Online Handwritten Assamese Characters Dataset',\n",
       " '  PubChem Bioassay Data',\n",
       " '  Record Linkage Comparison Patterns',\n",
       " '  Communities and Crime Unnormalized',\n",
       " '  Vertebral Column',\n",
       " '  EMG Physical Action Data Set',\n",
       " '  Vicon Physical Action Data Set',\n",
       " '  Amazon Commerce reviews set',\n",
       " '  Amazon Access Samples',\n",
       " '  Reuter_50_50',\n",
       " '  Farm Ads',\n",
       " '  DBWorld e-mails',\n",
       " '  KEGG Metabolic Relation Network (Directed)',\n",
       " '  KEGG Metabolic Reaction Network (Undirected)',\n",
       " '  Bank Marketing',\n",
       " '  YouTube Comedy Slam Preference Data',\n",
       " '  Gas Sensor Array Drift Dataset',\n",
       " '  ILPD (Indian Liver Patient Dataset)',\n",
       " '  OPPORTUNITY Activity Recognition',\n",
       " '  Nomao',\n",
       " '  SMS Spam Collection',\n",
       " '  Skin Segmentation',\n",
       " '  Planning Relax',\n",
       " '  PAMAP2 Physical Activity Monitoring',\n",
       " '  Restaurant & consumer data',\n",
       " '  CNAE-9',\n",
       " '  Individual household electric power consumption',\n",
       " '  seeds',\n",
       " '  Northix',\n",
       " '  QtyT40I10D100K',\n",
       " '  Legal Case Reports',\n",
       " '  Human Activity Recognition Using Smartphones',\n",
       " '  One-hundred plant species leaves data set',\n",
       " '  Energy efficiency',\n",
       " '  Yacht Hydrodynamics',\n",
       " '  Fertility',\n",
       " '  Daphnet Freezing of Gait',\n",
       " '  3D Road Network (North Jutland, Denmark)',\n",
       " '  ISTANBUL STOCK EXCHANGE',\n",
       " '  Buzz in social media',\n",
       " '  First-order theorem proving',\n",
       " '  Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       " '  Gas sensor arrays in open sampling settings',\n",
       " '  Climate Model Simulation Crashes',\n",
       " '  MicroMass',\n",
       " '  QSAR biodegradation',\n",
       " '  BLOGGER',\n",
       " '  Daily and Sports Activities',\n",
       " '  User Knowledge Modeling',\n",
       " '  Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       " '  NYSK',\n",
       " '  Turkiye Student Evaluation',\n",
       " \"  ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       " '  EEG Eye State',\n",
       " '  Physicochemical Properties of Protein Tertiary Structure',\n",
       " '  seismic-bumps',\n",
       " '  banknote authentication',\n",
       " '  USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       " '  YouTube Multiview Video Games Dataset',\n",
       " '  Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       " '  Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       " '  SkillCraft1 Master Table Dataset',\n",
       " '  Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       " '  SML2010',\n",
       " '  Bike Sharing Dataset',\n",
       " '  Predict keywords activities in a online social media',\n",
       " '  Thoracic Surgery Data',\n",
       " '  EMG dataset in Lower Limb',\n",
       " '  SUSY',\n",
       " '  HIGGS',\n",
       " '  Qualitative_Bankruptcy',\n",
       " '  LSVT Voice Rehabilitation',\n",
       " '  Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       " '  Wilt',\n",
       " '  User Identification From Walking Activity',\n",
       " '  Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       " '  Leaf',\n",
       " '  Dresses_Attribute_Sales',\n",
       " '  Tamilnadu Electricity Board Hourly Readings',\n",
       " '  Airfoil Self-Noise',\n",
       " '  Wholesale customers',\n",
       " '  Twitter Data set for Arabic Sentiment Analysis',\n",
       " '  Combined Cycle Power Plant',\n",
       " '  Urban Land Cover',\n",
       " '  Diabetes 130-US hospitals for years 1999-2008',\n",
       " '  Bach Choral Harmony',\n",
       " '  StoneFlakes',\n",
       " '  Tennis Major Tournament Match Statistics',\n",
       " '  Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       " '  Gesture Phase Segmentation',\n",
       " '  Perfume Data',\n",
       " '  BlogFeedback',\n",
       " '  REALDISP Activity Recognition Dataset',\n",
       " '  Newspaper and magazine images segmentation dataset',\n",
       " '  AAAI 2014 Accepted Papers',\n",
       " '  Gas sensor array under flow modulation',\n",
       " '  Gas sensor array exposed to turbulent gas mixtures',\n",
       " '  UJIIndoorLoc',\n",
       " '  Sentence Classification',\n",
       " '  Dow Jones Index',\n",
       " '  sEMG for Basic Hand movements',\n",
       " '  AAAI 2013 Accepted Papers',\n",
       " '  Geographical Original of Music',\n",
       " '  Condition Based Maintenance of Naval Propulsion Plants',\n",
       " '  Grammatical Facial Expressions',\n",
       " '  NoisyOffice',\n",
       " '  MHEALTH Dataset',\n",
       " '  Student Performance',\n",
       " '  ElectricityLoadDiagrams20112014',\n",
       " '  Gas sensor array under dynamic gas mixtures',\n",
       " '  microblogPCU',\n",
       " '  Firm-Teacher_Clave-Direction_Classification',\n",
       " '  Dataset for Sensorless Drive Diagnosis',\n",
       " '  TV News Channel Commercial Detection Dataset',\n",
       " '  Phishing Websites',\n",
       " '  Greenhouse Gas Observing Network',\n",
       " '  Diabetic Retinopathy Debrecen Data Set',\n",
       " '  HIV-1 protease cleavage',\n",
       " '  Sentiment Labelled Sentences',\n",
       " '  Online News Popularity',\n",
       " '  Forest type mapping',\n",
       " '  wiki4HE',\n",
       " '  Online Video Characteristics and Transcoding Time Dataset',\n",
       " '  Chronic_Kidney_Disease',\n",
       " '  Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       " '  Folio',\n",
       " '  Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       " '  Cuff-Less Blood Pressure Estimation',\n",
       " '  Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       " '  Mice Protein Expression',\n",
       " '  UJIIndoorLoc-Mag',\n",
       " '  Heterogeneity Activity Recognition',\n",
       " '  Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       " '  HEPMASS',\n",
       " '  Indoor User Movement Prediction from RSS data',\n",
       " '  Open University Learning Analytics dataset',\n",
       " '  default of credit card clients',\n",
       " '  Mesothelioma’s disease data set',\n",
       " '  Online Retail',\n",
       " '  SIFT10M',\n",
       " '  GPS Trajectories',\n",
       " '  Detect Malacious Executable(AntiVirus)',\n",
       " '  Occupancy Detection',\n",
       " '  Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       " '  News Aggregator',\n",
       " '  Air Quality',\n",
       " '  Twin gas sensor arrays',\n",
       " '  Gas sensors for home activity monitoring',\n",
       " '  Facebook Comment Volume Dataset',\n",
       " '  Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       " '  Polish companies bankruptcy data',\n",
       " '  Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       " '  Dota2 Games Results',\n",
       " '  Facebook metrics',\n",
       " '  UbiqLog (smartphone lifelogging)',\n",
       " '  NIPS Conference Papers 1987-2015',\n",
       " '  HTRU2',\n",
       " '  Drug consumption (quantified)',\n",
       " '  Appliances energy prediction',\n",
       " '  Miskolc IIS Hybrid IPS',\n",
       " '  KDC-4007 dataset Collection',\n",
       " '  Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       " '  DrivFace',\n",
       " '  Website Phishing',\n",
       " '  YouTube Spam Collection',\n",
       " '  Beijing PM2.5 Data',\n",
       " '  Cargo 2000 Freight Tracking and Tracing',\n",
       " '  Cervical cancer (Risk Factors)',\n",
       " '  Quality Assessment of Digital Colposcopies',\n",
       " '  KASANDR',\n",
       " '  FMA: A Dataset For Music Analysis',\n",
       " '  Air quality',\n",
       " '  Epileptic Seizure Recognition',\n",
       " '  Devanagari Handwritten Character Dataset',\n",
       " '  Stock portfolio performance',\n",
       " '  MoCap Hand Postures',\n",
       " '  Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       " '  Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       " '  PM2.5 Data of Five Chinese Cities',\n",
       " '  Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       " '  Sales_Transactions_Dataset_Weekly',\n",
       " '  Las Vegas Strip',\n",
       " '  Eco-hotel',\n",
       " '  MEU-Mobile KSD',\n",
       " '  Crowdsourced Mapping',\n",
       " '  gene expression cancer RNA-Seq',\n",
       " '  Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       " '  chestnut – LARVIC',\n",
       " '  Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       " '  Motion Capture Hand Postures',\n",
       " '  Anuran Calls (MFCCs)',\n",
       " '  TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       " '  Gastrointestinal Lesions in Regular Colonoscopy',\n",
       " '  Daily Demand Forecasting Orders',\n",
       " '  Paper Reviews',\n",
       " '  extention of Z-Alizadeh sani dataset',\n",
       " '  Z-Alizadeh Sani',\n",
       " '  Dynamic Features of VirusShare Executables',\n",
       " '  IDA2016Challenge',\n",
       " '  DSRC Vehicle Communications',\n",
       " '  Mturk User-Perceived Clusters over Images',\n",
       " '  Character Font Images',\n",
       " '  DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       " '  Autistic Spectrum Disorder Screening Data for Children',\n",
       " '  Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       " '  APS Failure at Scania Trucks',\n",
       " '  Wireless Indoor Localization',\n",
       " '  HCC Survival',\n",
       " '  CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       " '  University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       " '  Autism Screening Adult',\n",
       " '  Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       " '  Immunotherapy Dataset',\n",
       " '  Cryotherapy Dataset',\n",
       " '  OCT data & Color Fundus Images of Left & Right Eyes',\n",
       " '  Discrete Tone Image Dataset',\n",
       " '  News Popularity in Multiple Social Media Platforms',\n",
       " '  Ultrasonic flowmeter diagnostics',\n",
       " '  ICMLA 2014 Accepted Papers Data Set',\n",
       " '  BLE RSSI Dataset for Indoor localization and Navigation',\n",
       " '  Container Crane Controller Data Set',\n",
       " '  Residential Building Data Set',\n",
       " '  Health News in Twitter',\n",
       " '  chipseq',\n",
       " '  SGEMM GPU kernel performance',\n",
       " '  Repeat Consumption Matrices',\n",
       " '  detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       " '  Absenteeism at work',\n",
       " '  SCADI',\n",
       " '  Condition monitoring of hydraulic systems',\n",
       " '  Carbon Nanotubes',\n",
       " '  Optical Interconnection Network',\n",
       " '  Sports articles for objectivity analysis',\n",
       " '  Breast Cancer Coimbra',\n",
       " '  GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       " '  Dishonest Internet users Dataset',\n",
       " '  Victorian Era Authorship Attribution',\n",
       " '  Simulated Falls and Daily Living Activities Data Set',\n",
       " '  Multimodal Damage Identification for Humanitarian Computing',\n",
       " '  EEG Steady-State Visual Evoked Potential Signals',\n",
       " '  Roman Urdu Data Set',\n",
       " '  Avila',\n",
       " '  PANDOR',\n",
       " '  Drug Review Dataset (Druglib.com)',\n",
       " '  Drug Review Dataset (Drugs.com)',\n",
       " '  Physical Unclonable Functions',\n",
       " '  Superconductivty Data',\n",
       " '  WESAD (Wearable Stress and Affect Detection)',\n",
       " '  GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       " '  Student Academics Performance',\n",
       " '  Online Shoppers Purchasing Intention Dataset',\n",
       " '  PMU-UD',\n",
       " \"  Parkinson's Disease Classification\",\n",
       " '  Electrical Grid Stability Simulated Data',\n",
       " '  Caesarian Section Classification Dataset',\n",
       " '  BAUM-1',\n",
       " '  BAUM-2',\n",
       " '  Audit Data',\n",
       " '  BuddyMove Data Set',\n",
       " '  Real estate valuation data set',\n",
       " '  Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       " '  Somerville Happiness Survey',\n",
       " '  2.4 GHZ Indoor Channel Measurements',\n",
       " '  EMG data for gestures',\n",
       " '  Parking Birmingham',\n",
       " '  Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       " '  Travel Reviews',\n",
       " '  Tarvel Review Ratings',\n",
       " '  Rice Leaf Diseases',\n",
       " '  Gas sensor array temperature modulation',\n",
       " '  Facebook Live Sellers in Thailand',\n",
       " '  Parkinson Dataset with replicated acoustic features',\n",
       " '  Metro Interstate Traffic Volume',\n",
       " '  Query Analytics Workloads Dataset',\n",
       " '  Wave Energy Converters',\n",
       " '  PPG-DaLiA',\n",
       " '  Alcohol QCM Sensor Dataset',\n",
       " '  Divorce Predictors data set',\n",
       " '  Incident management process enriched event log',\n",
       " '  Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       " '  MEx',\n",
       " '  Beijing Multi-Site Air-Quality Data',\n",
       " '  Online Retail II',\n",
       " '  Hepatitis C Virus (HCV) for Egyptian patients',\n",
       " '  QSAR fish toxicity',\n",
       " '  QSAR aquatic toxicity',\n",
       " '  Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       " '  WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       " '  QSAR oral toxicity',\n",
       " '  QSAR androgen receptor',\n",
       " '  QSAR Bioconcentration classes dataset',\n",
       " '  QSAR fish bioconcentration factor (BCF)',\n",
       " '  A study of Asian Religious and Biblical Texts',\n",
       " '  Real-time Election Results: Portugal 2019',\n",
       " '  Bias correction of numerical prediction model temperature forecast',\n",
       " '  Bar Crawl: Detecting Heavy Drinking',\n",
       " '  Kitsune Network Attack Dataset',\n",
       " '  Shoulder Implant X-Ray Manufacturer Classification',\n",
       " '  Speaker Accent Recognition',\n",
       " '  Heart failure clinical records',\n",
       " '  Deepfakes: Medical Image Tamper Detection',\n",
       " '  selfBACK',\n",
       " '  South German Credit',\n",
       " '  Exasens',\n",
       " '  Swarm Behaviour',\n",
       " '  Crop mapping using fused optical-radar data set',\n",
       " '  BitcoinHeistRansomwareAddressDataset',\n",
       " '  Facebook Large Page-Page Network',\n",
       " '  Amphibians',\n",
       " '  Early stage diabetes risk prediction dataset.',\n",
       " '  Turkish Spam V01',\n",
       " '  Stock keeping units',\n",
       " '  Demand Forecasting for a store',\n",
       " '  Detect Malware Types',\n",
       " '  Wave Energy Converters',\n",
       " '  Youtube cookery channels viewers comments in Hinglish',\n",
       " '  Pedestrian in Traffic Dataset',\n",
       " '  Cervical Cancer Behavior Risk',\n",
       " '  Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       " '  Divorce Predictors data set',\n",
       " '  3W dataset',\n",
       " '  Malware static and dynamic features VxHeaven and Virus Total',\n",
       " '  Internet Firewall Data',\n",
       " '  User Profiling and Abusive Language Detection Dataset',\n",
       " '  Estimation of obesity levels based on eating habits and physical condition',\n",
       " '  Rice (Cammeo and Osmancik)',\n",
       " '  Vehicle routing and scheduling problems',\n",
       " '  Algerian Forest Fires Dataset',\n",
       " '  Breath Metabolomics',\n",
       " '  Horton General Hospital',\n",
       " '  UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       " '  Gas Turbine CO and NOx Emission Data Set',\n",
       " '  Activity recognition using wearable physiological measurements',\n",
       " '  clickstream data for online shopping',\n",
       " '  CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       " '  Apartment for rent classified',\n",
       " '  : Simulated Data set of Iraqi tourism places',\n",
       " '  Nasarian CAD Dataset',\n",
       " '  Monolithic Columns in Troad and Mysia Region',\n",
       " '  Bar Crawl: Detecting Heavy Drinking',\n",
       " '  Seoul Bike Sharing Demand',\n",
       " '  Person Classification Gait Data',\n",
       " '  Shill Bidding Dataset',\n",
       " '  Iranian Churn Dataset',\n",
       " '  Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " '  Bone marrow transplant: children',\n",
       " '  Exasens',\n",
       " '  COVID-19 Surveillance',\n",
       " '  Refractive errors',\n",
       " '  Shoulder Implant X-Ray Manufacturer Classification',\n",
       " '  CLINC150',\n",
       " '  HCV data',\n",
       " '  Taiwanese Bankruptcy Prediction',\n",
       " '  South German Credit (UPDATE)',\n",
       " '  IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       " '  Guitar Chords finger positions',\n",
       " '  Russian Corpus of Biographical Texts',\n",
       " '  Codon usage',\n",
       " '  Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       " '  Myocardial infarction complications',\n",
       " '  Hungarian Chickenpox Cases',\n",
       " '  Simulated data for survival modelling',\n",
       " '  Student Performance on an entrance examination',\n",
       " '  Chemical Composition of Ceramic Samples',\n",
       " '  Labeled Text Forum Threads Dataset',\n",
       " '  Stock keeping units',\n",
       " '  BLE RSSI dataset for Indoor localization',\n",
       " '  Basketball dataset',\n",
       " '  GitHub MUSAE',\n",
       " '  Anticancer peptides',\n",
       " '  Monolithic Columns in Troad and Mysia Region',\n",
       " '  Gender by Name',\n",
       " '  Iranian Churn Dataset',\n",
       " '  Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       " '  Shoulder Implant Manufacture Classification',\n",
       " '  LastFM Asia Social Network',\n",
       " '  Wheat kernels',\n",
       " '  Productivity Prediction of Garment Employees',\n",
       " '  Multi-view Brain Networks',\n",
       " '  LastFM Asia Social Network',\n",
       " '  Wisesight Sentiment Corpus',\n",
       " '  AI4I 2020 Predictive Maintenance Dataset',\n",
       " '  Dry Bean Dataset',\n",
       " '  in-vehicle coupon recommendation',\n",
       " '  Gait Classification',\n",
       " '  Wikipedia Math Essentials',\n",
       " '  Wikipedia Math Essentials',\n",
       " '  Synchronous Machine Data Set',\n",
       " '  Average Localization Error (ALE) in sensor node localization process in WSNs',\n",
       " '  9mers from cullpdb',\n",
       " '  TamilSentiMix',\n",
       " '  Accelerometer',\n",
       " '  Synchronous Machine Data Set',\n",
       " '  Pedal Me Bicycle Deliveries',\n",
       " '  Turkish Headlines Dataset',\n",
       " '  Secondary Mushroom Dataset',\n",
       " '  Power consumption of Tetouan city',\n",
       " '  Raisin Dataset',\n",
       " '  Steel Industry Energy Consumption Dataset',\n",
       " '  Gender Gap in Spanish WP',\n",
       " '  Non verbal tourists data',\n",
       " '  Roman Urdu Sentiment Analysis Dataset (RUSAD)',\n",
       " '  TUANDROMD ( Tezpur University Android Malware Dataset)',\n",
       " '  Higher Education Students Performance Evaluation Dataset',\n",
       " '  Risk Factor prediction of Chronic Kidney Disease',\n",
       " '  Lab Test',\n",
       " '  Shoulder Implant Manufacture Classification',\n",
       " '  Rocket League Skillshots Data Set',\n",
       " '  Sepsis survival minimal clinical records',\n",
       " '  Water Quality Prediction',\n",
       " '  Traffic Flow Forecasting',\n",
       " '  sentiment analysis in Saudi Arabia about distance education during Covid-19',\n",
       " '  Kain Tradisional Sambas',\n",
       " '  Image Recognition Task Execution Times in Mobile Edge Computing',\n",
       " '  REWEMA',\n",
       " '  REJAFADA',\n",
       " '  Steel Industry Energy Consumption Dataset',\n",
       " '  Influenza outbreak event prediction via Twitter data',\n",
       " '  Turkish Music Emotion Dataset',\n",
       " '  Maternal Health Risk Data Set',\n",
       " '  Room Occupancy Estimation',\n",
       " '  Image Recognition Task Execution Times in Mobile Edge Computing']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d8=[]\n",
    "d8tag=driver8.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[1]')\n",
    "for i in d8tag:\n",
    "    d8.append(i.text)\n",
    "d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d302a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print(len(d8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27bc618",
   "metadata": {},
   "outputs": [],
   "source": [
    "url8=[]\n",
    "url=driver.find_elements(By.XPATH,'')\n",
    "for i in url:\n",
    "    url8.append(i.get_attribute('href'))\n",
    "    time.sleep(3)\n",
    "url8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad0bd252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Types',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Univariate, Time-Series ',\n",
       " 'Multivariate, Spatial ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Data-Generator ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Sequential ',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Spatio-temporal ',\n",
       " 'Transactional, Sequential ',\n",
       " 'Image ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Relational ',\n",
       " 'Multivariate, Relational ',\n",
       " 'Sequential ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Text, Sequential ',\n",
       " 'Image ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Time-Series, Domain-Theory ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Text, Domain-Theory ',\n",
       " 'Univariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate, Text ',\n",
       " 'Sequential ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Sequential, Text ',\n",
       " 'Multivariate, Univariate, Time-Series ',\n",
       " 'Time-Series, Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Domain-Theory ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series, Text ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Univariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Univariate, Sequential, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series, Domain-Theory ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Text ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " ' ',\n",
       " 'Sequential ',\n",
       " 'Univariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Univariate, Domain-Theory ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Univariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Text ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series, Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Sequential, Time-Series ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Univariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Sequential ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Text ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Sequential, Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Text ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Sequential ',\n",
       " ' ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Time-Series ',\n",
       " 'Text ',\n",
       " 'Univariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Text ',\n",
       " 'Multivariate ',\n",
       " 'Univariate, Sequential, Time-Series ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Univariate ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt8=[]\n",
    "try:\n",
    "    dt8tag=driver8.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[2]')\n",
    "    for i in dt8tag:\n",
    "          dt8.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    dt8.append('NA')\n",
    "dt8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0539b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print(len(dt8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1846110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Default Task',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Recommender-Systems ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Function-Learning ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Relational-Learning ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Recommender-Systems ',\n",
       " 'Classification ',\n",
       " 'Regression, Description ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering, Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression, Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering, Causa ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering, Causal-Discovery ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " ' ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Recommendation ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Causal-Discovery ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Causal-Discovery ',\n",
       " 'Clustering ',\n",
       " 'Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression, Causal-Discovery ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification, Regression ',\n",
       " 'Classification, Regression, Clustering ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification, Clustering ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Classification ',\n",
       " 'Regression ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t8=[]\n",
    "try:\n",
    "    t8tag=driver8.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[3]')\n",
    "    for i in t8tag:\n",
    "          t8.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    t8.append('NA')\n",
    "t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "969850d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print(len(t8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba465b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attribute Types',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Real, Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer, Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Categorical ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Categorical, Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Categorical ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Real ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer ',\n",
       " 'Integer, Real ',\n",
       " 'Integer, Real ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " 'Real ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at8=[]\n",
    "try:\n",
    "    at8tag=driver8.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[4]')\n",
    "    for i in at8tag:\n",
    "          at8.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    at8.append('NA')\n",
    "at8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b1d136c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print(len(at8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a12ec6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Instances',\n",
       " '4177 ',\n",
       " '48842 ',\n",
       " '798 ',\n",
       " '37711 ',\n",
       " '452 ',\n",
       " '6000 ',\n",
       " '226 ',\n",
       " '226 ',\n",
       " '398 ',\n",
       " '205 ',\n",
       " '294 ',\n",
       " '625 ',\n",
       " '16 ',\n",
       " '286 ',\n",
       " '699 ',\n",
       " '198 ',\n",
       " '569 ',\n",
       " '108 ',\n",
       " '1728 ',\n",
       " '48842 ',\n",
       " ' ',\n",
       " '3196 ',\n",
       " '28056 ',\n",
       " ' ',\n",
       " '100 ',\n",
       " '67557 ',\n",
       " '690 ',\n",
       " '125 ',\n",
       " '209 ',\n",
       " '1473 ',\n",
       " '581012 ',\n",
       " '512 ',\n",
       " '366 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '132 ',\n",
       " '336 ',\n",
       " '194 ',\n",
       " '352 ',\n",
       " '214 ',\n",
       " '306 ',\n",
       " '160 ',\n",
       " '303 ',\n",
       " '155 ',\n",
       " '368 ',\n",
       " ' ',\n",
       " '2310 ',\n",
       " '3279 ',\n",
       " '351 ',\n",
       " '150 ',\n",
       " '7797 ',\n",
       " '104 ',\n",
       " '57 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '20000 ',\n",
       " '345 ',\n",
       " ' ',\n",
       " '32 ',\n",
       " '148 ',\n",
       " '209 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " '106 ',\n",
       " '128 ',\n",
       " '3190 ',\n",
       " '432 ',\n",
       " '202 ',\n",
       " '2000 ',\n",
       " '8124 ',\n",
       " '476 ',\n",
       " '6598 ',\n",
       " '12960 ',\n",
       " ' ',\n",
       " '5473 ',\n",
       " '5620 ',\n",
       " '10992 ',\n",
       " '90 ',\n",
       " '339 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '167 ',\n",
       " '15 ',\n",
       " '1389 ',\n",
       " '307 ',\n",
       " '47 ',\n",
       " '23 ',\n",
       " '531 ',\n",
       " '4601 ',\n",
       " '267 ',\n",
       " '267 ',\n",
       " '76 ',\n",
       " ' ',\n",
       " '1000 ',\n",
       " '151 ',\n",
       " '958 ',\n",
       " '7200 ',\n",
       " '10 ',\n",
       " '285 ',\n",
       " '435 ',\n",
       " '527 ',\n",
       " '5000 ',\n",
       " '5000 ',\n",
       " '178 ',\n",
       " '1484 ',\n",
       " '101 ',\n",
       " ' ',\n",
       " '20000 ',\n",
       " '6650 ',\n",
       " '2565 ',\n",
       " '2458285 ',\n",
       " '299285 ',\n",
       " '340 ',\n",
       " '68040 ',\n",
       " ' ',\n",
       " '122 ',\n",
       " '178080 ',\n",
       " '50672 ',\n",
       " '640 ',\n",
       " '9000 ',\n",
       " '10104 ',\n",
       " '256932 ',\n",
       " '640 ',\n",
       " '191779 ',\n",
       " '4000000 ',\n",
       " ' ',\n",
       " '10000 ',\n",
       " '989818 ',\n",
       " '129000 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '21578 ',\n",
       " '463 ',\n",
       " '600 ',\n",
       " '332 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '690 ',\n",
       " '1000 ',\n",
       " '270 ',\n",
       " '6435 ',\n",
       " '2310 ',\n",
       " '58000 ',\n",
       " '946 ',\n",
       " '20008 ',\n",
       " '208 ',\n",
       " '528 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1024 ',\n",
       " '10080 ',\n",
       " '50400 ',\n",
       " '1025010 ',\n",
       " '19020 ',\n",
       " '1364 ',\n",
       " '961 ',\n",
       " '517 ',\n",
       " '200 ',\n",
       " '8000000 ',\n",
       " '1030 ',\n",
       " '606 ',\n",
       " '900 ',\n",
       " '2600 ',\n",
       " '1950 ',\n",
       " '13500 ',\n",
       " '4400 ',\n",
       " '2536 ',\n",
       " '300 ',\n",
       " '197 ',\n",
       " '2858 ',\n",
       " '748 ',\n",
       " '11640 ',\n",
       " '1593 ',\n",
       " '1567 ',\n",
       " '22632 ',\n",
       " '360 ',\n",
       " '103 ',\n",
       " '1994 ',\n",
       " '120 ',\n",
       " '4898 ',\n",
       " '2396130 ',\n",
       " '16772 ',\n",
       " '5875 ',\n",
       " '503 ',\n",
       " '51 ',\n",
       " '106 ',\n",
       " '2126 ',\n",
       " '5456 ',\n",
       " '8800 ',\n",
       " '164860 ',\n",
       " ' ',\n",
       " '1941 ',\n",
       " '130065 ',\n",
       " '515345 ',\n",
       " '440 ',\n",
       " ' ',\n",
       " '53500 ',\n",
       " '8235 ',\n",
       " ' ',\n",
       " '5749132 ',\n",
       " '2215 ',\n",
       " '310 ',\n",
       " '10000 ',\n",
       " '3000 ',\n",
       " '1500 ',\n",
       " '30000 ',\n",
       " '2500 ',\n",
       " '4143 ',\n",
       " '64 ',\n",
       " '53414 ',\n",
       " '65554 ',\n",
       " '45211 ',\n",
       " '1138562 ',\n",
       " '13910 ',\n",
       " '583 ',\n",
       " '2551 ',\n",
       " '34465 ',\n",
       " '5574 ',\n",
       " '245057 ',\n",
       " '182 ',\n",
       " '3850505 ',\n",
       " '138 ',\n",
       " '1080 ',\n",
       " '2075259 ',\n",
       " '210 ',\n",
       " '115 ',\n",
       " '3960456 ',\n",
       " ' ',\n",
       " '10299 ',\n",
       " '1600 ',\n",
       " '768 ',\n",
       " '308 ',\n",
       " '100 ',\n",
       " '237 ',\n",
       " '434874 ',\n",
       " '536 ',\n",
       " '140000 ',\n",
       " '6118 ',\n",
       " '165632 ',\n",
       " '18000 ',\n",
       " '540 ',\n",
       " '931 ',\n",
       " '1055 ',\n",
       " '100 ',\n",
       " '9120 ',\n",
       " '403 ',\n",
       " '111740 ',\n",
       " '10421 ',\n",
       " '5820 ',\n",
       " '403 ',\n",
       " '14980 ',\n",
       " '45730 ',\n",
       " '2584 ',\n",
       " '1372 ',\n",
       " '306 ',\n",
       " '120000 ',\n",
       " '13910 ',\n",
       " '2747 ',\n",
       " '3395 ',\n",
       " '39242 ',\n",
       " '4137 ',\n",
       " '17389 ',\n",
       " '51 ',\n",
       " '470 ',\n",
       " '132 ',\n",
       " '5000000 ',\n",
       " '11000000 ',\n",
       " '250 ',\n",
       " '126 ',\n",
       " ' ',\n",
       " '4889 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '340 ',\n",
       " '501 ',\n",
       " '45781 ',\n",
       " '1503 ',\n",
       " '440 ',\n",
       " '2000 ',\n",
       " '9568 ',\n",
       " '168 ',\n",
       " '100000 ',\n",
       " '5665 ',\n",
       " '79 ',\n",
       " '127 ',\n",
       " '1040 ',\n",
       " '9900 ',\n",
       " '560 ',\n",
       " '60021 ',\n",
       " '1419 ',\n",
       " '101 ',\n",
       " '399 ',\n",
       " '58 ',\n",
       " '180 ',\n",
       " '21048 ',\n",
       " ' ',\n",
       " '750 ',\n",
       " '3000 ',\n",
       " '150 ',\n",
       " '1059 ',\n",
       " '11934 ',\n",
       " '27965 ',\n",
       " '216 ',\n",
       " '120 ',\n",
       " '649 ',\n",
       " '370 ',\n",
       " '4178504 ',\n",
       " '221579 ',\n",
       " '10800 ',\n",
       " '58509 ',\n",
       " '129685 ',\n",
       " '2456 ',\n",
       " '2921 ',\n",
       " '1151 ',\n",
       " '6590 ',\n",
       " '3000 ',\n",
       " '39797 ',\n",
       " '326 ',\n",
       " '913 ',\n",
       " '168286 ',\n",
       " '400 ',\n",
       " '314080 ',\n",
       " '637 ',\n",
       " '1710671 ',\n",
       " '12000 ',\n",
       " '10929 ',\n",
       " '1080 ',\n",
       " '40000 ',\n",
       " '43930257 ',\n",
       " '230318 ',\n",
       " '10500000 ',\n",
       " '13197 ',\n",
       " ' ',\n",
       " '30000 ',\n",
       " '324 ',\n",
       " '541909 ',\n",
       " '11164866 ',\n",
       " '163 ',\n",
       " '373 ',\n",
       " '20560 ',\n",
       " '40 ',\n",
       " '422937 ',\n",
       " '9358 ',\n",
       " '640 ',\n",
       " '919438 ',\n",
       " '40949 ',\n",
       " '5744 ',\n",
       " '10503 ',\n",
       " '42240 ',\n",
       " '102944 ',\n",
       " '500 ',\n",
       " '9782222 ',\n",
       " '11463 ',\n",
       " '17898 ',\n",
       " '1885 ',\n",
       " '19735 ',\n",
       " '1540 ',\n",
       " '4007 ',\n",
       " '153540 ',\n",
       " '606 ',\n",
       " '1353 ',\n",
       " '1956 ',\n",
       " '43824 ',\n",
       " '3942 ',\n",
       " '858 ',\n",
       " '287 ',\n",
       " '17764280 ',\n",
       " '106574 ',\n",
       " '9358 ',\n",
       " '11500 ',\n",
       " '92000 ',\n",
       " '315 ',\n",
       " '78095 ',\n",
       " '130 ',\n",
       " '74 ',\n",
       " '52854 ',\n",
       " '77 ',\n",
       " '811 ',\n",
       " '504 ',\n",
       " '401 ',\n",
       " '2856 ',\n",
       " '10546 ',\n",
       " '801 ',\n",
       " '1540 ',\n",
       " '1451 ',\n",
       " '1075 ',\n",
       " '78095 ',\n",
       " '7195 ',\n",
       " '3600 ',\n",
       " '76 ',\n",
       " '60 ',\n",
       " '405 ',\n",
       " '303 ',\n",
       " '303 ',\n",
       " '107888 ',\n",
       " '76000 ',\n",
       " '10000 ',\n",
       " '180 ',\n",
       " '745000 ',\n",
       " '12234 ',\n",
       " '292 ',\n",
       " '104 ',\n",
       " '60000 ',\n",
       " '2000 ',\n",
       " '165 ',\n",
       " '217 ',\n",
       " '1175 ',\n",
       " '704 ',\n",
       " '75128 ',\n",
       " '90 ',\n",
       " '90 ',\n",
       " '50 ',\n",
       " '71 ',\n",
       " '93239 ',\n",
       " '540 ',\n",
       " '105 ',\n",
       " '6611 ',\n",
       " '15 ',\n",
       " '372 ',\n",
       " '58000 ',\n",
       " '4960 ',\n",
       " '241600 ',\n",
       " '130000 ',\n",
       " '7062606 ',\n",
       " '740 ',\n",
       " '70 ',\n",
       " '2205 ',\n",
       " '10721 ',\n",
       " '640 ',\n",
       " '1000 ',\n",
       " '116 ',\n",
       " '1672 ',\n",
       " '322 ',\n",
       " '93600 ',\n",
       " '3060 ',\n",
       " '5879 ',\n",
       " '9200 ',\n",
       " '20000 ',\n",
       " '20867 ',\n",
       " ' ',\n",
       " '4143 ',\n",
       " '215063 ',\n",
       " '6000000 ',\n",
       " '21263 ',\n",
       " '63000000 ',\n",
       " '10190 ',\n",
       " '300 ',\n",
       " '12330 ',\n",
       " '5180 ',\n",
       " '756 ',\n",
       " '10000 ',\n",
       " '80 ',\n",
       " '1184 ',\n",
       " '1047 ',\n",
       " '777 ',\n",
       " '249 ',\n",
       " '414 ',\n",
       " ' ',\n",
       " '143 ',\n",
       " '7840 ',\n",
       " '30000 ',\n",
       " '35717 ',\n",
       " '135 ',\n",
       " '980 ',\n",
       " '5456 ',\n",
       " '120 ',\n",
       " '4095000 ',\n",
       " '7051 ',\n",
       " '240 ',\n",
       " '48204 ',\n",
       " '260000 ',\n",
       " '288000 ',\n",
       " '8300000 ',\n",
       " '125 ',\n",
       " '170 ',\n",
       " '141712 ',\n",
       " '3916 ',\n",
       " '6262 ',\n",
       " '420768 ',\n",
       " '1067371 ',\n",
       " '1385 ',\n",
       " '908 ',\n",
       " '546 ',\n",
       " '13956534 ',\n",
       " '15630426 ',\n",
       " '8992 ',\n",
       " '1687 ',\n",
       " '779 ',\n",
       " '1056 ',\n",
       " '590 ',\n",
       " '21643 ',\n",
       " '7750 ',\n",
       " '14057567 ',\n",
       " '27170754 ',\n",
       " '597 ',\n",
       " '329 ',\n",
       " '299 ',\n",
       " '20000 ',\n",
       " '26136 ',\n",
       " '1000 ',\n",
       " '399 ',\n",
       " '24017 ',\n",
       " '325834 ',\n",
       " '2916697 ',\n",
       " '22470 ',\n",
       " '189 ',\n",
       " '520 ',\n",
       " '826 ',\n",
       " '2279 ',\n",
       " '28764 ',\n",
       " '7107 ',\n",
       " '288000 ',\n",
       " '9800 ',\n",
       " '4760 ',\n",
       " '72 ',\n",
       " '1450 ',\n",
       " '170 ',\n",
       " '1984 ',\n",
       " '2955 ',\n",
       " '65532 ',\n",
       " '65919 ',\n",
       " '2111 ',\n",
       " '3810 ',\n",
       " '18 ',\n",
       " '244 ',\n",
       " '104 ',\n",
       " '139 ',\n",
       " '360177 ',\n",
       " '36733 ',\n",
       " '4480 ',\n",
       " '165474 ',\n",
       " '1985 ',\n",
       " '10000 ',\n",
       " '232 ',\n",
       " '150 ',\n",
       " '11 ',\n",
       " '14057567 ',\n",
       " '8760 ',\n",
       " '48 ',\n",
       " '6321 ',\n",
       " '3150 ',\n",
       " '17256 ',\n",
       " '187 ',\n",
       " '399 ',\n",
       " '14 ',\n",
       " '467 ',\n",
       " '597 ',\n",
       " '23700 ',\n",
       " '615 ',\n",
       " '6819 ',\n",
       " '1000 ',\n",
       " ' ',\n",
       " '2633 ',\n",
       " '200 ',\n",
       " '13028 ',\n",
       " '800 ',\n",
       " '1700 ',\n",
       " '521 ',\n",
       " '120000 ',\n",
       " '666 ',\n",
       " '88 ',\n",
       " '200 ',\n",
       " '2279 ',\n",
       " '23570 ',\n",
       " '10000 ',\n",
       " '37700 ',\n",
       " '1850 ',\n",
       " '11 ',\n",
       " '147270 ',\n",
       " '3150 ',\n",
       " '17256 ',\n",
       " '597 ',\n",
       " '7624 ',\n",
       " '314 ',\n",
       " '1197 ',\n",
       " '70 ',\n",
       " '7624 ',\n",
       " '26737 ',\n",
       " '10000 ',\n",
       " '13611 ',\n",
       " '12684 ',\n",
       " '48 ',\n",
       " '731 ',\n",
       " '731 ',\n",
       " '557 ',\n",
       " '107 ',\n",
       " '158716 ',\n",
       " '15744 ',\n",
       " '153000 ',\n",
       " '557 ',\n",
       " '36 ',\n",
       " '4200 ',\n",
       " '61069 ',\n",
       " '52417 ',\n",
       " '900 ',\n",
       " '35040 ',\n",
       " '4746 ',\n",
       " '73 ',\n",
       " '11000 ',\n",
       " '4465 ',\n",
       " '145 ',\n",
       " '202 ',\n",
       " '221 ',\n",
       " '597 ',\n",
       " '298 ',\n",
       " '110341 ',\n",
       " '705 ',\n",
       " '2101 ',\n",
       " '1765 ',\n",
       " '150 ',\n",
       " '4000 ',\n",
       " '6272 ',\n",
       " '1996 ',\n",
       " '35040 ',\n",
       " '75840 ',\n",
       " '400 ',\n",
       " '1014 ',\n",
       " '10129 ',\n",
       " '4000 ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt8=[]\n",
    "try:\n",
    "    nt8tag=driver8.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[5]')\n",
    "    for i in nt8tag:\n",
    "          nt8.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    nt8.append('NA')\n",
    "nt8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be5d712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print(len(nt8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d064f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Attributes',\n",
       " '8 ',\n",
       " '14 ',\n",
       " '38 ',\n",
       " '294 ',\n",
       " '279 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '69 ',\n",
       " '8 ',\n",
       " '26 ',\n",
       " '1 ',\n",
       " '4 ',\n",
       " '4 ',\n",
       " '9 ',\n",
       " '10 ',\n",
       " '34 ',\n",
       " '32 ',\n",
       " '13 ',\n",
       " '6 ',\n",
       " '14 ',\n",
       " '22 ',\n",
       " '36 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '42 ',\n",
       " '15 ',\n",
       " ' ',\n",
       " '9 ',\n",
       " '9 ',\n",
       " '54 ',\n",
       " '39 ',\n",
       " '33 ',\n",
       " '20 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '8 ',\n",
       " '30 ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '3 ',\n",
       " '5 ',\n",
       " '75 ',\n",
       " '19 ',\n",
       " '27 ',\n",
       " ' ',\n",
       " '19 ',\n",
       " '1558 ',\n",
       " '34 ',\n",
       " '4 ',\n",
       " '617 ',\n",
       " '12 ',\n",
       " '16 ',\n",
       " '7 ',\n",
       " '4 ',\n",
       " '16 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '56 ',\n",
       " '18 ',\n",
       " '8 ',\n",
       " '22 ',\n",
       " ' ',\n",
       " '58 ',\n",
       " ' ',\n",
       " '61 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '649 ',\n",
       " '22 ',\n",
       " '168 ',\n",
       " '168 ',\n",
       " '8 ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '64 ',\n",
       " '16 ',\n",
       " '8 ',\n",
       " '17 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '72 ',\n",
       " '4 ',\n",
       " '6 ',\n",
       " '10 ',\n",
       " '35 ',\n",
       " '35 ',\n",
       " '4 ',\n",
       " '102 ',\n",
       " '57 ',\n",
       " '22 ',\n",
       " '44 ',\n",
       " '45 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '9 ',\n",
       " '21 ',\n",
       " '32 ',\n",
       " '17 ',\n",
       " '16 ',\n",
       " '38 ',\n",
       " '21 ',\n",
       " '40 ',\n",
       " '13 ',\n",
       " '8 ',\n",
       " '17 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '15 ',\n",
       " '22 ',\n",
       " '68 ',\n",
       " '40 ',\n",
       " '17 ',\n",
       " '89 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '12 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '86 ',\n",
       " '72 ',\n",
       " '61 ',\n",
       " '12 ',\n",
       " '481 ',\n",
       " '42 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '90 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '14 ',\n",
       " '20 ',\n",
       " '13 ',\n",
       " '36 ',\n",
       " '19 ',\n",
       " '9 ',\n",
       " '18 ',\n",
       " '4 ',\n",
       " '60 ',\n",
       " '10 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '4 ',\n",
       " '3 ',\n",
       " '11 ',\n",
       " '11 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '13 ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " '9 ',\n",
       " '101 ',\n",
       " '10000 ',\n",
       " '20000 ',\n",
       " '100000 ',\n",
       " '5000 ',\n",
       " '500 ',\n",
       " '73 ',\n",
       " '43 ',\n",
       " '23 ',\n",
       " '3 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " '256 ',\n",
       " '591 ',\n",
       " '70 ',\n",
       " '91 ',\n",
       " '10 ',\n",
       " '128 ',\n",
       " '6 ',\n",
       " '12 ',\n",
       " '3231961 ',\n",
       " '5409 ',\n",
       " '26 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10 ',\n",
       " '23 ',\n",
       " '24 ',\n",
       " '13 ',\n",
       " '8 ',\n",
       " ' ',\n",
       " '27 ',\n",
       " '50 ',\n",
       " '90 ',\n",
       " '138672 ',\n",
       " ' ',\n",
       " '386 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '147 ',\n",
       " '6 ',\n",
       " '8 ',\n",
       " '27 ',\n",
       " '10000 ',\n",
       " '20000 ',\n",
       " '10000 ',\n",
       " '54877 ',\n",
       " '4702 ',\n",
       " '24 ',\n",
       " '29 ',\n",
       " '17 ',\n",
       " '3 ',\n",
       " '128 ',\n",
       " '10 ',\n",
       " '242 ',\n",
       " '120 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '13 ',\n",
       " '52 ',\n",
       " '47 ',\n",
       " '857 ',\n",
       " '9 ',\n",
       " '7 ',\n",
       " '200 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '561 ',\n",
       " '64 ',\n",
       " '8 ',\n",
       " '7 ',\n",
       " '10 ',\n",
       " '9 ',\n",
       " '4 ',\n",
       " '8 ',\n",
       " '77 ',\n",
       " '51 ',\n",
       " '18 ',\n",
       " '1950000 ',\n",
       " '18 ',\n",
       " '1300 ',\n",
       " '41 ',\n",
       " '6 ',\n",
       " '5625 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '33 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '9 ',\n",
       " '19 ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '1000000 ',\n",
       " '129 ',\n",
       " ' ',\n",
       " '20 ',\n",
       " '152 ',\n",
       " '24 ',\n",
       " '16 ',\n",
       " '35 ',\n",
       " '17 ',\n",
       " '5 ',\n",
       " '18 ',\n",
       " '28 ',\n",
       " '7 ',\n",
       " '309 ',\n",
       " '3 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '13 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '8 ',\n",
       " '2 ',\n",
       " '4 ',\n",
       " '148 ',\n",
       " '55 ',\n",
       " '17 ',\n",
       " '8 ',\n",
       " '42 ',\n",
       " '26 ',\n",
       " '50 ',\n",
       " '2 ',\n",
       " '281 ',\n",
       " '120 ',\n",
       " ' ',\n",
       " '6 ',\n",
       " '120432 ',\n",
       " '150000 ',\n",
       " '529 ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '2500 ',\n",
       " '5 ',\n",
       " '68 ',\n",
       " '16 ',\n",
       " '100 ',\n",
       " '216 ',\n",
       " '23 ',\n",
       " '33 ',\n",
       " '140256 ',\n",
       " '19 ',\n",
       " '20 ',\n",
       " '20 ',\n",
       " '49 ',\n",
       " '12 ',\n",
       " '30 ',\n",
       " '5232 ',\n",
       " '20 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '61 ',\n",
       " '27 ',\n",
       " '53 ',\n",
       " '11 ',\n",
       " '25 ',\n",
       " '0 ',\n",
       " '20 ',\n",
       " '9 ',\n",
       " '3 ',\n",
       " '561 ',\n",
       " '82 ',\n",
       " '13 ',\n",
       " '16 ',\n",
       " '13 ',\n",
       " '28 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '24 ',\n",
       " '34 ',\n",
       " '8 ',\n",
       " '128 ',\n",
       " '15 ',\n",
       " '513 ',\n",
       " '7 ',\n",
       " '7 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '480000 ',\n",
       " '11 ',\n",
       " '54 ',\n",
       " '561 ',\n",
       " '64 ',\n",
       " '6 ',\n",
       " '116 ',\n",
       " '19 ',\n",
       " ' ',\n",
       " '5812 ',\n",
       " '9 ',\n",
       " '32 ',\n",
       " '29 ',\n",
       " '67 ',\n",
       " ' ',\n",
       " '25 ',\n",
       " '6400 ',\n",
       " '10 ',\n",
       " '5 ',\n",
       " '13 ',\n",
       " '98 ',\n",
       " '36 ',\n",
       " '69 ',\n",
       " '2158859 ',\n",
       " '518 ',\n",
       " '15 ',\n",
       " '179 ',\n",
       " ' ',\n",
       " '12 ',\n",
       " '38 ',\n",
       " '65 ',\n",
       " '102 ',\n",
       " '86 ',\n",
       " '7 ',\n",
       " '53 ',\n",
       " '20 ',\n",
       " '1 ',\n",
       " '71 ',\n",
       " '29 ',\n",
       " '20531 ',\n",
       " '65 ',\n",
       " '3 ',\n",
       " '22 ',\n",
       " '38 ',\n",
       " '22 ',\n",
       " '4814 ',\n",
       " '698 ',\n",
       " '13 ',\n",
       " '10 ',\n",
       " '59 ',\n",
       " '56 ',\n",
       " '482 ',\n",
       " '171 ',\n",
       " '5 ',\n",
       " '500 ',\n",
       " '411 ',\n",
       " '8519 ',\n",
       " '21 ',\n",
       " '21 ',\n",
       " '171 ',\n",
       " '7 ',\n",
       " '49 ',\n",
       " '12 ',\n",
       " '3 ',\n",
       " '21 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '7 ',\n",
       " '2 ',\n",
       " '11 ',\n",
       " '11 ',\n",
       " '173 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '3 ',\n",
       " '105 ',\n",
       " '25000 ',\n",
       " ' ',\n",
       " '18 ',\n",
       " '21000 ',\n",
       " '115 ',\n",
       " '21 ',\n",
       " '206 ',\n",
       " '43680 ',\n",
       " '8 ',\n",
       " '10 ',\n",
       " '59 ',\n",
       " '10 ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '1000 ',\n",
       " '138 ',\n",
       " ' ',\n",
       " '16 ',\n",
       " '2 ',\n",
       " '10 ',\n",
       " ' ',\n",
       " '8 ',\n",
       " '6 ',\n",
       " '129 ',\n",
       " '81 ',\n",
       " '12 ',\n",
       " '6 ',\n",
       " '22 ',\n",
       " '18 ',\n",
       " '9 ',\n",
       " '754 ',\n",
       " '14 ',\n",
       " '5 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '18 ',\n",
       " '7 ',\n",
       " '7 ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '4 ',\n",
       " '18 ',\n",
       " '11 ',\n",
       " '25 ',\n",
       " ' ',\n",
       " '20 ',\n",
       " '12 ',\n",
       " '46 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '49 ',\n",
       " '11 ',\n",
       " '8 ',\n",
       " '54 ',\n",
       " '36 ',\n",
       " '3916 ',\n",
       " '710 ',\n",
       " '18 ',\n",
       " '8 ',\n",
       " '29 ',\n",
       " '7 ',\n",
       " '9 ',\n",
       " '37 ',\n",
       " '6 ',\n",
       " '1024 ',\n",
       " '1024 ',\n",
       " '14 ',\n",
       " '7 ',\n",
       " '8265 ',\n",
       " '29 ',\n",
       " '25 ',\n",
       " '3 ',\n",
       " '115 ',\n",
       " '1 ',\n",
       " '12 ',\n",
       " '13 ',\n",
       " '200000 ',\n",
       " '6 ',\n",
       " '21 ',\n",
       " '4 ',\n",
       " '2400 ',\n",
       " '175 ',\n",
       " '10 ',\n",
       " '4714 ',\n",
       " '23 ',\n",
       " '17 ',\n",
       " '2 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '280 ',\n",
       " '49 ',\n",
       " '3 ',\n",
       " '14 ',\n",
       " '19 ',\n",
       " ' ',\n",
       " '54 ',\n",
       " '8 ',\n",
       " '1087 ',\n",
       " '12 ',\n",
       " '3 ',\n",
       " '17 ',\n",
       " '8 ',\n",
       " '9 ',\n",
       " '12 ',\n",
       " '1656 ',\n",
       " '6 ',\n",
       " '2 ',\n",
       " '11 ',\n",
       " '533 ',\n",
       " '14 ',\n",
       " '84 ',\n",
       " '22 ',\n",
       " '16 ',\n",
       " '52 ',\n",
       " '19 ',\n",
       " '3 ',\n",
       " '14 ',\n",
       " '321 ',\n",
       " '13 ',\n",
       " '13 ',\n",
       " '55 ',\n",
       " '39 ',\n",
       " '4 ',\n",
       " '7 ',\n",
       " '79 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '14 ',\n",
       " '96 ',\n",
       " '21 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '2 ',\n",
       " '69 ',\n",
       " '9 ',\n",
       " '124 ',\n",
       " '20 ',\n",
       " '25 ',\n",
       " '11 ',\n",
       " '19 ',\n",
       " '9 ',\n",
       " '9 ',\n",
       " '5 ',\n",
       " '7 ',\n",
       " '4006 ',\n",
       " '2 ',\n",
       " '19 ',\n",
       " '4 ',\n",
       " '13 ',\n",
       " '55 ',\n",
       " '1 ',\n",
       " '7842 ',\n",
       " '15 ',\n",
       " '15 ',\n",
       " '70 ',\n",
       " '7842 ',\n",
       " '4 ',\n",
       " '14 ',\n",
       " '17 ',\n",
       " '23 ',\n",
       " '321 ',\n",
       " '1068 ',\n",
       " '1068 ',\n",
       " '5 ',\n",
       " '6 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " '5 ',\n",
       " '5 ',\n",
       " '15 ',\n",
       " '7 ',\n",
       " '21 ',\n",
       " '9 ',\n",
       " '8 ',\n",
       " '11 ',\n",
       " '21 ',\n",
       " '22 ',\n",
       " '2 ',\n",
       " '241 ',\n",
       " '33 ',\n",
       " '29 ',\n",
       " '7 ',\n",
       " '1 ',\n",
       " ' ',\n",
       " '4 ',\n",
       " '11 ',\n",
       " '47 ',\n",
       " '10 ',\n",
       " '3 ',\n",
       " '2 ',\n",
       " '632 ',\n",
       " '6826 ',\n",
       " '11 ',\n",
       " '525 ',\n",
       " '50 ',\n",
       " '7 ',\n",
       " '16 ',\n",
       " '2 ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n8=[]\n",
    "try:\n",
    "    n8tag=driver8.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[6]')\n",
    "    for i in n8tag:\n",
    "          n8.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    n8.append('NA')\n",
    "n8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c21e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print(len(n8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e353ec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " '1995 ',\n",
       " '1996 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1988 ',\n",
       " '1992 ',\n",
       " '1995 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " '1997 ',\n",
       " '1996 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1995 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1997 ',\n",
       " '1998 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " '1990 ',\n",
       " '1987 ',\n",
       " '1999 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " ' ',\n",
       " '1990 ',\n",
       " '1998 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1994 ',\n",
       " '1990 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1991 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1996 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1992 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '2001 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1991 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2002 ',\n",
       " ' ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '2003 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1997 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1993 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '2006 ',\n",
       " '2006 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y8=[]\n",
    "try:\n",
    "    y8tag=driver8.find_elements(By.XPATH,'//table[@border=\"1\"]/tbody/tr/td[7]')\n",
    "    for i in y8tag:\n",
    "          y8.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    y8.append('NA')\n",
    "y8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "016d3913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print(len(y8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43df543d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1995 ',\n",
       " '1996 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1988 ',\n",
       " '1992 ',\n",
       " '1995 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " '1997 ',\n",
       " '1996 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1995 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1987 ',\n",
       " '1997 ',\n",
       " '1998 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " '1990 ',\n",
       " '1987 ',\n",
       " '1999 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " ' ',\n",
       " '1990 ',\n",
       " '1998 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1994 ',\n",
       " '1990 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1991 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1988 ',\n",
       " '1990 ',\n",
       " '1996 ',\n",
       " '1995 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1992 ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1994 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1995 ',\n",
       " '1998 ',\n",
       " '1998 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1989 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '2001 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " '1993 ',\n",
       " '1997 ',\n",
       " '1991 ',\n",
       " '1987 ',\n",
       " '1994 ',\n",
       " '1988 ',\n",
       " '1987 ',\n",
       " '1993 ',\n",
       " '1988 ',\n",
       " '1988 ',\n",
       " '1991 ',\n",
       " '1996 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2002 ',\n",
       " ' ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '2000 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '1998 ',\n",
       " '1999 ',\n",
       " '2001 ',\n",
       " '1999 ',\n",
       " ' ',\n",
       " '2003 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1997 ',\n",
       " '1999 ',\n",
       " '1999 ',\n",
       " '1998 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " ' ',\n",
       " '1993 ',\n",
       " '1990 ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1989 ',\n",
       " '2006 ',\n",
       " '2006 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2007 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2008 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2009 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2010 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2011 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2012 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2013 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2014 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2015 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2016 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2017 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2016 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2018 ',\n",
       " '2018 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2019 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2021 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2020 ',\n",
       " '2021 ',\n",
       " '2021 ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y88=y8[1:]\n",
    "y88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d197beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Task</th>\n",
       "      <th>No.of Instances</th>\n",
       "      <th>No.of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Abalone</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Annealing</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twit...</td>\n",
       "      <td>Influenza outbreak event prediction via Twit...</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mo...</td>\n",
       "      <td>Image Recognition Task Execution Times in Mo...</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617    Influenza outbreak event prediction via Twit...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621    Image Recognition Task Execution Times in Mo...   \n",
       "\n",
       "                                             Data Type                  Task  \\\n",
       "0                                              Abalone       Classification    \n",
       "1                                                Adult       Classification    \n",
       "2                                            Annealing       Classification    \n",
       "3                         Anonymous Microsoft Web Data  Recommender-Systems    \n",
       "4                                           Arrhythmia       Classification    \n",
       "..                                                 ...                   ...   \n",
       "617    Influenza outbreak event prediction via Twit...       Classification    \n",
       "618                      Turkish Music Emotion Dataset       Classification    \n",
       "619                      Maternal Health Risk Data Set       Classification    \n",
       "620                          Room Occupancy Estimation       Classification    \n",
       "621    Image Recognition Task Execution Times in Mo...           Regression    \n",
       "\n",
       "                  Attribute Task No.of Instances No.of Attributes   Year  \n",
       "0    Categorical, Integer, Real            4177                8   1995   \n",
       "1          Categorical, Integer           48842               14   1996   \n",
       "2    Categorical, Integer, Real             798               38          \n",
       "3                   Categorical           37711              294   1998   \n",
       "4    Categorical, Integer, Real             452              279   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "617               Integer, Real           75840              525   2020   \n",
       "618               Integer, Real             400               50   2020   \n",
       "619                                        1014                7   2020   \n",
       "620                        Real           10129               16   2021   \n",
       "621                        Real            4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame({'Dataset Name':d8[1:],'Data Type':d8[1:],'Task':t8[1:],'Attribute Task':at8[1:],'No.of Instances':nt8[1:],'No.of Attributes':n8[1:],'Year':y88})\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedbe8f",
   "metadata": {},
   "source": [
    "# PROBLEM NO.2 - TEAM INDIA'S INTERNATIONAL FIXTURES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba33f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67867578",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9=webdriver.Chrome(r\"chromedriver.exe\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "262c8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9.get(\"http://www.bcci.tv/\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b3c7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "search9=driver9.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "search9.click()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9351a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1st ODI ', '2nd ODI ', '3rd ODI ']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a9=[]\n",
    "a9tag=driver9.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in a9tag:\n",
    "    a9.append(i.text.split('-')[0])\n",
    "a9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57631169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wankhede Stadium',\n",
       " 'Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium',\n",
       " 'MA Chidambaram Stadium']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b9=[]\n",
    "b9tag=driver9.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for i in b9tag:\n",
    "    b9.append(i.text.split(',')[0])\n",
    "b9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93a20598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUSTRALIA TOUR OF INDIA 2023',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c9=[]\n",
    "c9tag=driver9.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in c9tag:\n",
    "    c9.append(i.text)\n",
    "c9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "132eaabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17 MAR 2023', '19 MAR 2023', '22 MAR 2023']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d9=[]\n",
    "d9tag=driver9.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in d9tag:\n",
    "    d9.append(i.text)\n",
    "d9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c317424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:30 PM IST', '1:30 PM IST', '1:30 PM IST']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f9=[]\n",
    "f9tag=driver9.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in f9tag:\n",
    "    f9.append(i.text)\n",
    "f9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "708b76b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>Wankhede Stadium</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium</td>\n",
       "      <td>19 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023</td>\n",
       "      <td>MA Chidambaram Stadium</td>\n",
       "      <td>22 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                        Series  \\\n",
       "0    1st ODI   AUSTRALIA TOUR OF INDIA 2023   \n",
       "1    2nd ODI   AUSTRALIA TOUR OF INDIA 2023   \n",
       "2    3rd ODI   AUSTRALIA TOUR OF INDIA 2023   \n",
       "\n",
       "                                              Place         Date         Time  \n",
       "0                                  Wankhede Stadium  17 MAR 2023  1:30 PM IST  \n",
       "1  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium  19 MAR 2023  1:30 PM IST  \n",
       "2                            MA Chidambaram Stadium  22 MAR 2023  1:30 PM IST  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9=pd.DataFrame({'Match Title':a9,'Series':c9,'Place':b9,'Date':d9,'Time':f9})\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0e1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
